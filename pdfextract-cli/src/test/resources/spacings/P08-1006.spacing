
cussion is the portability of training methods. When
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.640953, 0.0, 2.6518707, 0.0, 0.0, 2.6409607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.651886, 0.0, 2.6518707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6409607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.361206, 0.0, 0.0, 0.0]

training data in the target domain is available, as
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.627136, 0.0, 0.0, 0.0, 4.627136, 0.0, 4.638031, 0.0, 0.0, 4.627136, 0.0, 0.0, -0.18553162, 0.0, 0.0, 4.627136, 0.0, 0.0, 0.0, 0.0, 0.0, 4.627136, 0.0, 4.6380615, -0.20736694, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.096405, 0.0]

Figure 1: CoNLL-X dependency tree
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 3.08844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13946533, 2.4807434, 0.0, 0.0, 0.0]

trained to adapt to the target domain, and larger ac-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1102219, 0.0, 3.121132, 0.0, 0.0, 0.0, 0.0, 3.1211395, 0.0, 3.1211243, 0.0, 0.0, 3.1211548, 0.0, 0.0, -0.18551636, 0.0, 0.0, 3.0993042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2193604, 0.0, 0.0, 3.1211243, 0.0, 0.0, -0.18554688, 0.0, 0.0, 3.1102295, 0.0, 0.0]

curacy improvements are expected, if the training
	10.0
	[0.0, 0.0, 0.0, 0.0, -0.15277863, 4.4525223, 0.0, 0.0, 0.0, 0.0, -0.15278625, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4525146, 0.0, 0.0, 4.46344, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8890686, 0.0, 4.46344, 0.0, 0.0, 4.46344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

method is sufficiently general.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 4.987259, 0.0, 4.9872665, 0.0, 0.0, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.976349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

We will examine
	10.0
	[-0.8621216, 4.976349, 0.0, 0.0, 0.0, 4.998169, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0]

these two aspects of domain portability by compar-
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.1866074, 0.0, -0.098213196, 3.1756897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.186615, 0.0, 3.186615, 0.0, 0.0, 0.0, 0.0, 0.0, 3.186615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1975403, 0.0, 3.1865845, 0.0, 0.0, 0.0, 0.0, 0.0, -0.20736694]

ing the original parsers with the retrained parsers.
	10.0
	[0.0, 0.0, 2.7173538, 0.0, 0.0, 2.7282639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Syntactic Parsers and Their
	11.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9763794, -0.10757446, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9763794, 0.0, 0.0, 2.9883423, 0.0, 0.0, 0.0, 0.0]

Representations
	11.0
	[0.0, 0.0, 0.0, -0.21515656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Figure 2: Penn Treebank-style phrase structure tree
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 3.08844, 0.0, 0.0, 0.0, 2.4906921, -0.33877563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.480713, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0]

This paper focuses on eight representative parsers
	10.0
	[0.0, 0.0, 0.0, 4.343399, 0.0, 0.0, 0.0, 0.0, 4.354309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.343399, 0.0, 4.354309, 0.0, 0.0, 0.0, 0.0, 4.3434143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26190186, -0.16369629, 4.343384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

that are classified into three parsing frameworks:
	10.0
	[0.0, 0.0, 0.0, 5.140053, 0.0, 0.0, 5.150963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.140045, 0.0, 0.0, 0.0, 5.1509705, 0.0, 0.0, 0.0, 0.0, 5.140045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1509705, 0.0, 0.0, 0.0, 0.0, -0.26193237, -0.10913086, 0.0, 0.0, 0.0, 0.0]

dependency parsing, phrase structure parsing, and
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7213593, 0.0, 0.0, -0.098220825, 0.0, 0.0, 0.0, -0.03829956, 3.9736023, 0.0, 0.0, -0.152771, 0.0, 0.0, 3.7104492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.39285278, 3.721344, 0.0, 0.0, -0.098236084, 0.0, 0.0, 0.0, -0.05001831, 3.972351, 0.0, 0.0]

deep parsing. In general, our evaluation methodol-
	10.0
	[0.0, 0.0, 0.0, 3.3284836, 0.0, 0.0, -0.098220825, 0.0, 0.0, 0.0, -0.018417358, 5.194626, 0.0, 3.339386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4921875, 0.0, 0.0, 3.3394165, -0.26193237, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parser,
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, -0.42559814]

based on a probabilistic shift-reduce al-
	10.0
	[0.0, 0.0, 0.0, 0.0, 5.642029, 0.0, 5.6529236, 5.652954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.652954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.652954, 0.0, 0.0]

ogy can be applied to English parsers based on any
	10.0
	[0.0, 0.0, 3.197525, 0.0, 0.0, 3.208435, 0.0, 3.197525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.208435, 0.0, 3.1975098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.208435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.208435, 0.0, 0.0, 0.0, 0.0, 3.1975098, 0.0, 3.208435, 0.0, -0.152771]

gorithm extended by the pseudo-projective parsing
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7868042, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7868347, 0.0, 3.7868347, 0.0, 0.0, 3.79776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26193237, -0.16366577, 3.77594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

framework; however, in this paper, we chose parsers
	10.0
	[0.0, 0.0, 0.0, 0.0, -0.27282715, -0.098213196, 0.0, 0.0, 0.0, 2.5863953, 0.0, -0.2619171, 0.0, -0.27282715, -0.16369629, 0.0, -0.43652344, 2.5755005, 0.0, 2.5318298, 0.0, 0.0, 0.0, 2.5427399, 0.0, 0.0, 0.0, 0.0, -0.42559814, 2.57547, 0.0, 2.5427246, 0.0, 0.0, 0.0, 0.0, 2.5427246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

that were originally developed and trained with the
	10.0
	[0.0, 0.0, 0.0, 3.372139, 0.0, 0.0, 0.0, 3.383049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3721466, 0.0, -0.2619171, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3721313, 0.0, 0.0, 3.3830566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3721313, 0.0, 0.0, 0.0, 3.3830566, 0.0, 0.0]

Phrase structure parsing
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.18551636, 2.7173157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Penn Treebank or its variants, since such parsers can
	10.0
	[0.0, 0.0, 0.0, 2.4008713, -0.37104034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4008636, 0.0, 2.411789, 0.0, 0.0, 2.4117737, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4554443, 0.0, 0.0, 0.0, 0.0, 2.4117737, 0.0, 0.0, 0.0, 2.4118042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4118042, 0.0, 0.0]

be re-trained with GENIA, thus allowing for us to
	10.0
	[0.0, 3.8741302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8850403, 0.0, 0.0, 0.0, 3.8850555, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8850555, 0.0, 0.0, 0.0, 3.8741455, 0.0, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 3.8741455, 0.0, 0.0, 3.8850403, 0.0, 3.8850708, 0.0]

Owing largely to the Penn Treebank, the mainstream
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.215332, 0.0, 0.0, -0.18551636, 0.0, 0.0, 0.0, 2.2044373, 0.0, 2.215332, 0.0, 0.0, 2.2153625, 0.0, 0.0, 0.0, 2.215332, -0.3710327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3026428, 0.0, 0.0, 2.2153625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

investigate the effect of domain adaptation.
	10.0
	[0.0, -0.42560577, -0.16369629, 0.0, 0.0, 0.0, 0.0, -0.05456543, 0.0, 0.0, 2.7173462, 0.0, 0.0, 2.7282562, 0.0, -0.2619171, 0.0, 0.0, 0.0, 2.7173615, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

of data-driven parsing research has been dedicated
	10.0
	[0.0, 3.8414001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26193237, -0.16366577, 0.0, 3.8414001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8414001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.852295, 0.0, 0.0, 3.8414001, 0.0, 0.0, 0.0, 3.852295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

to the phrase structure parsing. These parsers output
	10.0
	[0.0, 2.55365, 0.0, 0.0, 2.5645752, 0.0, 0.0, 0.0, 0.0, 0.0, 2.55365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.55365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3284607, 0.0, 0.0, 0.0, 0.0, 2.5645752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.553711, 0.0, 0.0, 0.0, 0.0, 0.0]

Dependency parsing
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Penn Treebank-style phrase structure trees, although
	10.0
	[0.0, 0.0, 0.0, 2.3353882, -0.3710327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3354187, 0.0, 0.0, 0.0, 0.0, 0.0, 2.346283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3353882, 0.0, 0.0, 0.0, 0.0, 0.0, 2.422699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Because the shared tasks of CoNLL-2006 and
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0934906, 0.0, 0.0, 7.1044006, 0.0, 0.0, 0.0, 0.0, 0.0, 7.1044006, 0.0, 0.0, 0.0, 0.0, 7.1044006, 0.0, 7.1044006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.1044006, 0.0, 0.0]

function tags and empty categories are stripped off
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.546753, 0.0, 0.0, 0.0, 3.5576782, 0.0, 0.0, 3.5576782, 0.0, 0.0, 0.0, 0.0, 3.546753, 0.0, 0.0, 0.0, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 3.546753, 0.0, 0.0, 3.5467224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5576782, 0.0, -0.26190186]

CoNLL-2007 focused on data-driven dependency
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.347397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.347412, 0.0, 5.3473816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26193237, -0.16369629, 0.0, 5.347412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771]

parsing, it has recently been extensively studied in
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0050964, 0.0, 3.7540894, 0.0, 0.0, 3.7540894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7540894, 0.0, 0.0, 0.0, 3.7540894, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, -0.27282715, -0.16369629, 0.0, 0.0, 3.743164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7540894, 0.0]

are based on probabilistic CFGs, the parameteriza-
	10.0
	[0.0, 0.0, 3.5794678, 0.0, 0.0, 0.0, 0.0, 3.5794678, 0.0, 3.5903625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5794983, 0.0, 0.0, 0.0, 0.0, 3.79776, 0.0, 0.0, 3.5794983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parsing research.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.532921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The aim of dependency pars-
	10.0
	[0.0, 0.0, 5.532913, 0.0, 0.0, 5.5329285, 0.0, 5.5438232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 5.522003, 0.0, 0.0, 0.0, 0.0]

tion of the probabilistic model of each parser varies.
	10.0
	[0.0, 0.0, 0.0, 2.673706, 0.0, 2.6628113, 0.0, 0.0, 2.673706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.673706, 0.0, 0.0, 0.0, 0.0, 2.6736755, 0.0, 2.6627808, 0.0, 0.0, 0.0, 2.6736755, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6736755, -0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0]

ing is to compute a tree structure of a sentence
	10.0
	[0.0, 0.0, 5.4019623, 0.0, 5.41288, 0.0, 5.41288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4019623, 5.4128723, 0.0, 0.0, 0.0, 5.4128723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.401947, 0.0, 5.4128723, 5.4128723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

In this work, we chose the following four parsers.
	10.0
	[0.0, 2.7282715, 0.0, 0.0, 0.0, 2.7282715, -0.09820557, 0.0, 0.0, 0.0, 2.7173157, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.728302, 0.0, 0.0, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

where nodes are words, and edges represent the re-
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.2411804, 0.0, 0.0, 0.0, 0.0, 3.2411728, 0.0, 0.0, 3.2520905, -0.098236084, 0.0, 0.0, 0.0, 0.0, 3.361206, 0.0, 0.0, 3.2411804, 0.0, 0.0, 0.0, 0.0, 3.2521057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2411804, 0.0, 0.0, 3.2520752, 0.0, 0.0]

NO-RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

lations among words. Figure 1 shows a dependency
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8592224, 0.0, 0.0, 0.0, 0.0, 2.8701324, -0.09820557, 0.0, 0.0, 0.0, 0.0, 3.79776, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8701477, 2.8701477, 0.0, 0.0, -0.26193237, 0.0, 2.8592224, 2.8701172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771]

lexicalized PCFG model of phrase structure trees.
	10.0
	[0.0, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.590393, 0.0, 0.0, 0.0, 3.6013184, 0.0, 0.0, 0.0, 0.0, 3.6013184, 0.0, 3.6122131, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6013184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6013184, 0.0, 0.0, 0.0, 0.0, 0.0]

tree for the sentence “IL-8 recognizes and activates
	10.0
	[0.0, 0.0, 0.0, 3.2193527, 0.0, 0.0, 3.2302551, 0.0, 0.0, 3.2302704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2302856, 0.0, 0.0, 0.0, 0.0, 3.2193604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2302856, 0.0, 0.0, 3.2302551, 0.0, 0.0, 0.0, -0.26190186, -0.27282715, 0.0, 0.0, 0.0]

The probabilities of CFG rules are parameterized on
	10.0
	[0.0, 0.0, 2.5318298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5427246, 0.0, 2.5427246, 0.0, 0.0, 2.5318298, 0.0, 0.0, 0.0, 0.0, 2.5427246, 0.0, 0.0, 2.5318298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5427856, 0.0]

CXCR1.” An advantage of dependency parsing is
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, -0.7529907, 7.1589584, 0.0, 3.9941711, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9832458, 0.0, 3.9941711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 3.9832764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9941711, 0.0]

carefully hand-tuned extensive information such as
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.546753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5576782, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, -0.27279663, -0.16369629, 3.5358276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5576477, 0.0, 0.0, 0.0, 3.546753, 0.0]

that dependency trees are a reasonable approxima-
	10.0
	[0.0, 0.0, 0.0, 3.7977448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15278625, 3.7868347, 0.0, 0.0, 0.0, 0.0, 3.8086548, 0.0, 0.0, 3.7977448, 3.7977448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8086548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

lexical heads and symbols of ancestor/sibling nodes.
	10.0
	[0.0, -0.15280151, 0.0, 0.0, 0.0, 0.0, 2.4117737, 0.0, 0.0, 0.0, 0.0, 2.4335938, 0.0, 0.0, 2.422699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4335938, 0.0, 2.422699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4335938, 0.0, 0.0, 0.0, 0.0, 0.0]

tion of the semantics of sentences, and are readily
	10.0
	[0.0, 0.0, 0.0, 3.885048, 0.0, 3.885048, 0.0, 0.0, 3.895958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8850555, 0.0, 3.8959503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1796875, 0.0, 0.0, 3.8850708, 0.0, 0.0, 3.895935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

usable in NLP applications. Furthermore, the effi-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.7977448, 0.0, 3.8086548, 0.0, 0.0, 3.7977448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.613327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0705566, 0.0, 0.0, 3.8086548, 0.0, -0.26190186, 0.0]

RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0]

ciency of popular approaches to dependency pars-
	10.0
	[0.0, 0.0, 0.0, 0.0, -0.15278625, 4.1142197, 0.0, 4.136055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1251373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1360474, 0.0, 4.1251526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 4.125122, 0.0, 0.0, 0.0, 0.0]

ing parser. The reranker of this parser receives
	10.0
	[0.0, 0.0, 3.8741455, 0.0, 0.0, 0.0, 0.0, 0.0, -0.58932495, 6.7988586, 0.0, 0.0, 3.8741455, 0.0, 0.0, 0.0, 0.0, 0.0, -0.09817505, 0.0, 3.8632507, 0.0, 3.8632507, 0.0, 0.0, 0.0, 3.8741455, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8741455, 0.0, 0.0, 0.0, 0.0, -0.26190186, -0.16369629, 0.0]

ing compare favorable with those of phrase struc-
	10.0
	[0.0, 0.0, 4.256096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.267006, -0.098220825, -0.21826172, -0.21826172, 0.0, 0.0, 0.0, 0.0, 0.0, 4.245178, 0.0, 0.0, 0.0, 4.2669983, 0.0, 0.0, 0.0, 0.0, 4.2669983, 0.0, 4.256073, 0.0, 0.0, 0.0, 0.0, 0.0, 4.267029, 0.0, 0.0, 0.0, 0.0, 0.0]

best parse results from NO-RERANK, and selects
	9.55
	[0.0, 0.0, 0.0, 9.756714, 0.0, 0.0, 0.0, 0.0, 5.281891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2819214, 0.0, 0.0, 0.0, 5.255493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013549805, 5.281891, 0.0, 0.0, 5.281891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

ture parsing or deep parsing. While a number of ap-
	10.0
	[0.0, 0.0, 0.0, 2.739174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.739174, 0.0, 2.7391815, 0.0, 0.0, 0.0, 2.7391815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4266968, 0.0, 0.0, 0.0, 0.0, 2.7391663, 2.7391663, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7391663, 0.0, 2.7500916, 0.0, 0.0]

the most likely result by using a maximum entropy
	10.0
	[0.0, 0.0, 3.2957153, 0.0, 0.0, 0.0, 3.3066406, 0.0, 0.0, -0.09820557, 0.0, 0.0, 3.2957764, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2957458, 0.0, 3.3066711, 0.0, 0.0, 0.0, 0.0, 3.3066406, 3.2957764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3066406, 0.0, 0.0, 0.0, 0.0, 0.0, -0.09820557]

proaches have been proposed for dependency pars-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4594421, 0.0, -0.20735168, -0.16369629, 3.448532, 0.0, 0.0, 0.0, 3.4594421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4594421, 0.0, 0.0, 3.4594421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 3.4594116, 0.0, 0.0, 0.0, 0.0]

model with manually engineered features.
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

ing, this paper focuses on two typical methods.
	10.0
	[0.0, 0.0, 0.0, 2.7173538, 0.0, 0.0, 0.0, 2.7282639, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 2.7282562, 0.0, -0.098220825, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

BERKELEY
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The parameterization of this parser is op-
	10.0
	[0.0, 0.0, 3.9177856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.928711, 0.0, 3.928711, 0.0, 0.0, 0.0, 3.928711, 0.0, 0.0, 0.0, 0.0, 0.0, 3.928711, 0.0, 3.928711, 0.0, 0.0]

parser, based on the Eisner algorithm for projective
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, -0.42560577, 7.0668335, 0.0, 0.0, 0.0, 0.0, 2.5754852, 0.0, 2.5863953, 0.0, 0.0, 2.57547, 0.0, 0.0, 0.0, 0.0, 0.0, 2.58638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5755005, 0.0, 0.0, 2.5863953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26193237, -0.16369629]

http://www.cs.cmu.edu/˜sagae/parser/
	7.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

http://bllip.cs.brown.edu/resources.shtml
	7.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

order factorization.
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.7173462, -0.098220825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

We set
	8.0
	[-0.71698, 2.2316895, 0.0, 0.0]

in this paper.
	8.0
	[0.0, 2.231659, 0.0, 0.0, 0.0, 2.2406006, 0.0, 0.0, 0.0, 0.0, -0.48397827]

http://nlp.cs.berkeley.edu/Main.html#Parsing
	7.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

http://sourceforge.net/projects/mstparser
	7.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

This study demonstrates that IL-8 recognizes and
	9.0
	[0.0, 0.0, 0.0, 3.5766602, 0.0, 0.0, 0.0, 0.0, 3.5766602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5766602, 0.0, 0.0, 0.0, 3.5827332, 0.0, 0.0, 0.0, 3.5765076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5766907, 0.0, 0.0]

activates CXCR1, CXCR2, and the Duffy antigen
	9.0
	[0.0, 0.0, 0.0, -0.23913574, -0.24905396, 0.0, 0.0, 0.0, 2.4586487, 0.0, 0.0, 0.0, 0.0, -0.004547119, 2.4707031, 0.0, 0.0, 0.0, 0.0, -0.004547119, 2.4608154, 0.0, 0.0, 2.460785, 0.0, 0.0, 2.4670715, 0.0, 0.0, 0.0, 0.0, 2.460785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

by distinct mechanisms.
	9.0
	[0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The molar ratio of serum retinol-binding protein
	9.0
	[0.0, 0.0, 3.2677917, 0.0, 0.0, 0.0, 0.0, 3.2677917, 0.0, 0.0, 0.0, 0.0, 3.2578125, 0.0, 3.2677612, 0.0, 0.0, 0.0, 0.0, 3.2731934, -0.17932129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.257843, 0.0, -0.16937256, 0.0, 0.0, 0.0, 0.0]

sess vitamin A status during infection in hospi-
	9.0
	[0.0, 0.0, 0.0, 4.802063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.802063, 4.802063, 0.0, 0.0, 0.0, 0.0, 0.0, 4.802063, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8120117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.802063, 0.0, 4.802063, 0.0, 0.0, 0.0, 0.0, 0.0]

Figure 3: Predicate argument structure
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 3.0884552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, -0.16937256, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

talised children.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Figure 4: Sentences including protein names
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 3.08844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0]

timized automatically by assigning latent variables
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.841385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.841385, 0.0, 3.841385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.852295, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8414001, -0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

to each nonterminal node and estimating the param-
	10.0
	[0.0, 2.7064362, 0.0, 0.0, 0.0, 2.7064285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7064362, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 2.7064514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.706421, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0]

recognizes
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

eters of the latent variables by the EM algorithm
	10.0
	[0.0, 0.0, 0.0, 0.0, 4.670784, 0.0, 4.6817017, 0.0, 0.0, 4.6817017, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6707764, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.670807, 0.0, 4.6817017, 0.0, 0.0, 4.6707764, 0.0, 4.6817017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Figure 5: Dependency path
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 3.08844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13949585, 2.4807434, 0.0, 0.0, 0.0]

STANFORD
	8.0
	[0.0, -0.7976608, 0.0, 0.0, 0.0, 0.0, 0.0]

Unlike NO-RERANK, proba-
	9.181818
	[0.0, 0.0, 0.0, 0.0, -0.098236084, 3.8622742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02355957, 3.8850708, 0.0, 0.0, 0.0, 0.0, 0.0]

the parser output is embedded as statistical features
	10.0
	[0.0, 0.0, 3.1429443, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1429749, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1429749, 0.0, 3.1429443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1429749, 0.0, 3.1429749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1429749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

bilities are not parameterized on lexical heads.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173538, 0.0, 0.0, 2.7282562, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 2.7282715, 0.0, -0.152771, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0]

of a machine learning classifier. We run a classi-
	10.0
	[0.0, 4.256073, 4.245178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2561035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2561035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.58932495, 7.9556274, -0.8621216, 4.2342834, 0.0, 0.0, 4.256134, 4.2561035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

fier with features of every possible combination of a
	10.0
	[0.0, 0.0, 2.6518555, 0.0, 0.0, 0.0, 2.651886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.651886, 0.0, 2.651886, -0.26190186, -0.16369629, 0.0, 0.0, 2.6518555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.651886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6518555, 0.0, 2.6518555]

Deep parsing
	10.0
	[0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parser and a parse representation, by applying con-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.3394165, 0.0, 0.0, 3.3394165, 3.3394165, 0.0, 0.0, 0.0, 0.0, 3.3394165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5030823, 0.0, 3.3394165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3394165, 0.0, 0.0, 0.0]

Recent research developments have allowed for ef-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.4485245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4485474, 0.0, -0.26190186, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.437622, 0.0, -0.20733643, -0.16369629, 3.437622, 0.0, 0.0, 0.0, -0.26190186, 0.0, 0.0, 3.4485474, 0.0, 0.0, 3.4485168, 0.0, 0.0]

versions between representations when necessary.
	10.0
	[-0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0309143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.041809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.041809, 0.0, 0.0, 0.0, 5.041809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6984253]

ficient and robust deep parsing of real-world texts
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 4.157875, 0.0, 0.0, 4.1687927, 0.0, 0.0, -0.20735168, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1687927, 0.0, 4.1687927, 0.0, 0.0, 0.0, 0.0, 0.0, -0.09820557, 0.0, 0.0, 0.0, 4.1578674, 0.0, -0.152771, 0.0, 0.0]

We also measure the accuracy improvements ob-
	10.0
	[-0.8621216, 4.9981384, 0.0, 0.0, 0.0, 5.009094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.009094, 0.0, 0.0, 5.0090637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 4.998169, 0.0, 0.0, 0.0, 0.0, -0.15280151, -0.16366577, 0.0, 0.0, 0.0, 0.0, 0.0, 4.998169, 0.0, 0.0]

tained by parser retraining with GENIA, to examine
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.6846313, 0.0, 2.6955261, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6955261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6846313, 0.0, 0.0, 0.0, 2.6955261, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6846313, 0.0, 2.6955261, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0]

While deep parsers compute
	10.0
	[0.0, 0.0, 0.0, 0.0, 5.3910522, 0.0, 0.0, 0.0, 5.3910522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.3910522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

the domain portability, and to evaluate the effective-
	10.0
	[0.0, 0.0, 2.6846008, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6846008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6984558, 2.6846313, 0.0, 0.0, 2.6846313, 0.0, 2.6955261, -0.26190186, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 2.673706, 0.0, 0.0, 2.6846313, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, -0.27282715, -0.16369629, 0.0]

theory-specific syntactic/semantic structures, pred-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2669983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2779236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6707764, 0.0, 0.0, 0.0, 0.0]

ness of domain adaptation.
	10.0
	[0.0, 0.0, 0.0, 2.7282715, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parser evaluation and applications. PAS is a graph
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.6449661, -0.2619171, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6449585, 0.0, 0.0, 3.6558685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.1658936, -0.993103, 0.0, 3.6449585, 0.0, 3.6558838, 3.6558533, 0.0, 0.0, 0.0, 0.0]

PPI extraction
	10.0
	[0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

structure that represents syntactic/semantic relations
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4663544, 0.0, 0.0, 0.0, 2.4663544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4772644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.466339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

PPI extraction is an NLP task to identify protein
	10.0
	[0.0, 0.0, 4.8126526, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8017273, 0.0, 4.8126526, 0.0, 4.8126526, 0.0, 0.0, 4.8126526, 0.0, 0.0, 0.0, 4.812683, 0.0, 4.812683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8126526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

pairs that are mentioned as interacting in biomedical
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.4445496, 0.0, 0.0, 0.0, 2.4554138, 0.0, 0.0, 2.444519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4554138, 0.0, 2.444519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4554443, 0.0, 2.4445496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

similar to CoNLL dependencies, though PAS ex-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8235703, 0.0, 4.8344803, 0.0, 0.0, 0.0, 0.0, 4.8344727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.347412, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8344727, -0.993103, 0.0, 4.823578, -0.152771, 0.0]

papers. Because the number of biomedical papers is
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3612366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.651886, 0.0, 0.0, 2.6518555, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6518555, 0.0, 2.6627808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6518555, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6518555, 0.0]

presses deeper relations, and may include reentrant
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.383049, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3939667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.557663, 0.0, 0.0, 3.3830566, 0.0, 0.0, 3.3939514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3939514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

growing rapidly, it is impossible for biomedical re-
	10.0
	[0.0, 0.0, -0.26190186, 0.0, 0.0, 0.0, 3.3721313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6984253, 3.5358276, 0.0, 3.3939514, 0.0, 3.3830566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3830566, 0.0, 0.0, 3.3939514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3830566, 0.0, 0.0]

structures. In this work, we chose the two versions
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.118225, 0.0, 3.317566, 0.0, 0.0, 0.0, 3.3066406, -0.098220825, 0.0, 0.0, 0.0, 3.4485168, 0.0, 3.3066406, 0.0, 0.0, 0.0, 0.0, 3.3066711, 0.0, 0.0, 3.3066711, 0.0, -0.09820557, 3.3066406, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

searchers to read all papers relevant to their research;
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.138977, 0.0, 2.138977, 0.0, 0.0, 0.0, 2.1498718, 0.0, 0.0, 2.138977, 0.0, 0.0, 0.0, 0.0, 0.0, 2.138977, 0.0, 0.0, 0.0, -0.26193237, -0.27279663, 0.0, 0.0, 2.138977, 0.0, 2.1389465, 0.0, 0.0, 0.0, 0.0, 2.138977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

thus, there is an emerging need for reliable IE tech-
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.1102295, 0.0, 0.0, 0.0, 0.0, 3.033844, 0.0, 3.033844, 0.0, 3.0229187, 0.0, 0.0, 0.0, -0.18551636, 0.0, 0.0, 0.0, 3.0229187, 0.0, 0.0, 0.0, 3.033844, 0.0, 0.0, 3.033844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0338135, 0.0, 3.0338135, 0.0, 0.0, 0.0, 0.0]

nologies, such as PPI identification.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 2.7282715, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The HPSG parser that consists of an HPSG
	10.0
	[0.0, 0.0, 3.2520905, 0.0, 0.0, 0.0, 3.2630157, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2521057, 0.0, 0.0, 0.0, 3.2630005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2630005, 0.0, 3.2520752, 0.0, 3.26297, 0.0, 0.0, 0.0]

Figure 4 shows two sentences that include pro-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 4.310669, 4.3215637, 0.0, 0.0, -0.26190186, 0.0, 4.321594, 0.0, -0.09820557, 4.310669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.321594, 0.0, 0.0, 0.0, 4.321594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.321594, 0.0, 0.0, 0.0]

grammar extracted from the Penn Treebank, and
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.216446, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.216446, 0.0, 0.0, 0.0, 5.227356, 0.0, 0.0, 5.2164307, 0.0, 0.0, 0.0, 5.227356, -0.3710327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.838501, 0.0, 0.0]

tein names: the former sentence mentions a protein
	10.0
	[0.0, 0.0, 0.0, 3.1538696, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2561035, 0.0, 0.0, 3.1538696, 0.0, 0.0, 0.0, 0.0, 0.0, 3.164795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.164795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1538696, 3.164795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

a maximum entropy model trained with an HPSG
	10.0
	[4.190613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1906204, 0.0, 0.0, 0.0, 0.0, 0.0, -0.098236084, 4.1796875, 0.0, 0.0, 0.0, 0.0, 4.201523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.190613, 0.0, 0.0, 0.0, 4.190613, 0.0, 4.2015076, 0.0, 0.0, 0.0]

interaction, while the latter does not. Given a pro-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8304749, 0.0, 0.0, 0.0, 0.0, 3.6122131, 0.0, 0.0, 3.6122131, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6122131, 0.0, 0.0, 0.0, 3.6122131, 0.0, 0.0, 0.0, 6.0240173, 0.0, -0.26193237, -0.16366577, 0.0, 3.6013184, 3.6121826, 0.0, 0.0, 0.0]

treebank derived from the Penn Treebank.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173615, 0.0, 0.0, 0.0, -0.2619171, -0.15278625, 0.0, 2.7173462, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 2.728241, -0.3710327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

tein pair, PPI extraction is a task of binary classi-
	10.0
	[0.0, 0.0, 0.0, 4.114197, 0.0, 0.0, 0.0, -0.41470337, 4.452545, 0.0, 0.0, 4.1251526, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.103302, 0.0, 4.1251526, 4.1251526, 0.0, 0.0, 0.0, 4.1251526, 0.0, 4.114197, 0.0, 0.0, 0.0, 0.0, 0.0, 4.125183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

ENJU-GENIA
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parser
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0]

adapted
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

fication; for example, IL-8, CXCR1 is a positive
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1687927, 0.0, 0.0, 3.699524, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.134247, 0.0, 0.0, 0.0, 0.0, 3.928711, 0.0, 0.0, 0.0, 0.0, 7.9170837, 0.0, 3.6886292, 3.6886292, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26190186, -0.16363525]

biomedical texts, by the method of Hara et al.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0676575, 0.0, -0.15278625, 0.0, 0.0, 0.0, 6.9079742, 0.0, 6.0676727, 0.0, 0.0, 6.0785522, 0.0, 0.0, 0.0, 0.0, 0.0, 6.078583, 0.0, 6.0676575, 0.0, 0.0, 0.0, 6.078583, 0.0, 6.078583, 0.0, 0.0]

example, and RBP, TTR is a negative example.
	10.0
	[-0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.998169, 0.0, 0.0, 8.783783, 0.0, 0.0, -1.2004395, 4.5398254, 0.0, 0.0, 8.787598, 0.0, 4.55072, 4.561676, 0.0, -0.152771, -0.05456543, 0.0, 0.0, -0.27279663, -0.16366577, 4.5507507, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Because this parser is trained with both
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.965454, 0.0, 0.0, 0.0, 4.965439, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9654236, 0.0, 4.965454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9654236, 0.0, 0.0, 0.0, 4.9654236, 0.0, 0.0, 0.0]

Recent studies on PPI extraction demonstrated that
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.4921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4812622, 0.0, 3.4921875, 0.0, 0.0, 3.4921875, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4703674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4921875, 0.0, 0.0, 0.0]

WSJ and GENIA, we compare it parsers that are
	10.0
	[0.0, 0.0, 4.6053085, 0.0, 0.0, 4.6053085, 0.0, 0.0, 0.0, 0.0, 0.0, 4.616226, 0.0, 4.605316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.605316, 0.0, 4.616211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.605316, 0.0, 0.0, 0.0, 4.616211, 0.0, 0.0]

dependency relations between target proteins are ef-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 2.6082153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6191406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6191406, 0.0, 0.0, -0.18551636, 0.0, 0.0, 2.6191406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6191711, 0.0, 0.0, 2.6191406, 0.0, 0.0]

trenko and Adriaans, 2006; Erkan et al., 2007; Sætre
	10.0
	[0.0, 0.0, 0.0, 0.0, -0.09820557, 2.3572388, 0.0, 0.0, 2.3790283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.444519, 0.0, 0.0, 0.0, 0.0, 2.4881897, 0.0, 0.0, 0.0, 0.0, 2.3790588, 0.0, 2.3790588, 0.0, 0.0, 0.0, 2.4445496, 0.0, 0.0, 0.0, 0.0, 2.4882202, 0.0, 0.0, 0.0, 0.0]

Evaluation Methodology
	11.0
	[0.0, -0.10757446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9644318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

in Figure 4, a dependency parser outputs a depen-
	10.0
	[0.0, 3.9068909, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9068604, 0.0, 4.212433, 3.9068909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 3.8959656, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9068604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9177856, 3.9068604, 0.0, 0.0, 0.0, 0.0, 0.0]

In our approach to parser evaluation, we measure
	10.0
	[0.0, 4.4197845, 0.0, 0.0, 4.4197845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4198, 0.0, 4.4197845, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4198, -0.2619171, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8344727, 0.0, 4.4198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

dency tree shown in Figure 1. From this dependency
	10.0
	[0.0, 0.0, 0.0, -0.15280151, 2.3572388, 0.0, 0.0, 0.0, 2.3681335, 0.0, 0.0, -0.26193237, 0.0, 2.368103, 0.0, 2.3681335, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3681335, 0.0, 3.2630005, 0.0, 0.0, 0.0, 2.3790588, 0.0, 0.0, 0.0, 2.3681335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771]

the accuracy of a PPI extraction system, in which
	10.0
	[0.0, 0.0, 4.146965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15277863, 4.1360474, 0.0, 4.1469574, 4.1469574, 0.0, 0.0, 4.1578674, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1360474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.50708, 0.0, 4.1469727, 0.0, 0.0, 0.0, 0.0]

tree, we can extract a dependency path shown in Fig-
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.3026428, 0.0, 2.1935425, 0.0, 0.0, 2.2044373, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1826172, 2.2044373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 2.1826172, 0.0, 0.0, 0.0, 2.2044373, 0.0, 0.0, -0.26193237, 0.0, 2.1826172, 0.0, 2.2044067, 0.0, 0.0, 0.0]

http://nlp.stanford.edu/software/lex-parser.
	7.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

ure 5, which appears to be a strong clue in knowing
	10.0
	[0.0, 0.0, 2.9137878, 0.0, 2.9683533, 0.0, 0.0, 0.0, 0.0, 2.9247131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9137573, 0.0, 2.9247131, 0.0, 2.9246826, 2.9137878, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9247131, 0.0, 0.0, 0.0, 2.9137878, 0.0, 2.9247131, 0.0, 0.0, -0.26190186, 0.0, 0.0, 0.0]

that these proteins are mentioned as interacting.
	10.0
	[0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

http://www-tsujii.is.s.u-tokyo.ac.jp/enju/
	7.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Figure 6: Tree representation of a dependency path
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 3.0884705, -0.33874512, 0.0, 0.0, 2.4807281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 2.4906921, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13949585, 2.4807434, 0.0, 0.0, 0.0]

We follow the PPI extraction method of Sætre et
	10.0
	[-0.8730469, 3.2848282, 0.0, 0.0, 0.0, 0.0, -0.26190948, 3.2739105, 0.0, 0.0, 3.2957458, 0.0, 0.0, 3.2848358, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2848206, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2848206, 0.0, 3.2957458, 0.0, 0.0, 0.0, 0.0, 3.284851, 0.0]

Figure 7: Conversion of parse representations
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 3.0884705, 0.0, 0.0, -0.3885498, -0.14944458, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

resentations. Two types of features are incorporated
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6886063, -0.8621216, -0.10913086, 2.826477, 0.0, 0.0, 0.0, 0.0, 2.826477, 0.0, 2.8374023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.826477, 0.0, 0.0, 2.8373718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

in the classifier. The first is bag-of-words features,
	10.0
	[0.0, 3.5249176, 0.0, 0.0, 3.5249176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5893097, 5.772995, 0.0, 0.0, 3.5358276, 0.0, 0.0, 0.0, 3.5249329, 0.0, 3.5249329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.098236084, 0.0, 0.0, 0.0, 3.5249023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

which are regarded as a strong baseline for IE sys-
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.4812698, 0.0, 0.0, 3.4812622, 0.0, -0.15277863, -0.05456543, 0.0, 0.0, 0.0, 0.0, 3.4703522, 0.0, 3.4812775, 3.4812622, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4812622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4921875, 0.0, 0.0, 3.4812622, 0.0, 3.4812622, 0.0, 0.0, 0.0]

tems. Lemmas of words before, between and after
	10.0
	[0.0, 0.0, 0.0, 0.0, 5.914879, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5794983, 0.0, 3.579483, -0.098220825, 0.0, 0.0, 0.0, 3.557663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7868347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5794983, 0.0, 0.0, 3.5794678, 0.0, 0.0, 0.0, 0.0]

the pair of target proteins are included, and the linear
	10.0
	[0.0, 0.0, 2.215355, 0.0, 0.0, 0.0, 2.2262573, 0.0, 2.215355, 0.0, 0.0, -0.18551636, 0.0, 0.0, 2.2153625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2153625, 0.0, 0.0, 2.2262573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.324463, 0.0, 0.0, 2.2153625, 0.0, 0.0, 2.2262878, 0.0, 0.0, 0.0, 0.0, 0.0]

Figure 8: Head dependencies
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 3.08844, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

kernel is used for these features. These features are
	10.0
	[-0.098213196, 0.0, 0.0, 0.0, 0.0, 3.0774841, 0.0, 3.0883942, 0.0, 0.0, 0.0, 3.0883942, 0.0, 0.0, 3.0884094, 0.0, 0.0, 0.0, 0.0, 3.088379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4743347, 0.0, 0.0, 0.0, 0.0, 3.088379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0884094, 0.0, 0.0]

commonly included in all of the models. Filtering
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7431793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.743164, 0.0, 3.7540894, 0.0, 0.0, 3.7431793, 0.0, 3.7540894, 0.0, 0.0, 3.743164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.4496155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

by a stop-word list is not applied because this setting
	10.0
	[0.0, 2.313568, 2.313568, 0.0, 0.0, 0.0, 0.0, 0.0, -0.098220825, 0.0, 0.0, 2.313568, 0.0, 0.0, 0.0, 2.313568, 0.0, 2.3244934, 0.0, 0.0, 2.313568, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3244934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.313568, 0.0, 0.0, 0.0, 2.3244934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

sentation is also obtained from Penn Treebank-style
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8155823, 0.0, 2.826477, 0.0, 0.0, 0.0, 2.8155823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8155823, 0.0, 0.0, 0.0, 2.826477, 0.0, 0.0, 0.0, 2.8155823, -0.3710327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

trees by applying constituent-to-dependency conver-
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.2589722, 0.0, 2.2590027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.269928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 2.248108, 0.0, 0.0, -0.42559814, -0.16369629, 0.0, -0.21826172]

ting. The other type of feature is syntactic features.
	10.0
	[0.0, 0.0, 0.0, 0.0, 4.5070877, 0.0, 0.0, 3.1102142, 0.0, 0.0, 0.0, 0.0, 3.1102142, 0.0, 0.0, 0.0, 3.0993195, 0.0, 3.1102142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1102295, 0.0, 3.0993042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1102295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

For dependency-based parse representations, a de-
	10.0
	[-0.15277863, 0.0, 4.081482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.092392, 0.0, 0.0, 0.0, 0.0, 4.1033173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.44162, 4.103302, 0.0, 0.0]

noted, however, that this conversion cannot work
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 5.3255615, 0.0, -0.26190186, 0.0, -0.27279663, -0.16369629, 0.0, -0.43652344, 5.3255615, 0.0, 0.0, 0.0, 4.8126526, 0.0, 0.0, 0.0, 4.8126526, 0.0, 0.0, -0.42559814, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 4.801758, 0.0, 0.0, 0.0, 0.0, 0.0, 4.812622, -0.09820557, 0.0, 0.0]

pendency path is encoded as a flat tree as depicted in
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15277863, 2.3790436, 0.0, 0.0, 0.0, 2.4008636, 0.0, 2.4008636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4008636, 0.0, 2.400879, 2.400879, 0.0, 0.0, 2.400879, 0.0, 0.0, 0.0, 2.400879, 0.0, 2.4008484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.400879, 0.0]

perfectly with automatic parsing, because the con-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8741455, 0.0, 0.0, 0.0, 3.874115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8741455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8741455, 0.0, 0.0, 3.8741455, 0.0, 0.0, 0.0]

version program relies on function tags and empty
	10.0
	[-0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7540894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.77594, 0.0, 0.0, 0.0, 0.0, 0.0, 3.77594, 0.0, 3.7649841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.77594, 0.0, 0.0, 0.0, 3.7649841, 0.0, 0.0, 3.77594, 0.0, 0.0, 0.0, 0.0]

cause a tree kernel measures the similarity of trees
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.590393, 3.6013107, 0.0, 0.0, 0.0, 3.601303, -0.098220825, 0.0, 0.0, 0.0, 0.0, 3.590393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6012878, 0.0, 0.0, 3.6013184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6013184, 0.0, 3.6013184, 0.0, 0.0, 0.0, 0.0]

categories of the original Penn Treebank.
	10.0
	[0.0, 0.0, 0.0, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 2.7282715, -0.37106323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

by counting common subtrees, it is expected that the
	10.0
	[0.0, 2.411789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.422699, 0.0, 0.0, 0.0, 0.0, 0.0, 2.422699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.477234, 0.0, 2.422699, 0.0, 2.4117737, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4117737, 0.0, 0.0, 0.0, 2.422699, 0.0, 0.0]

system finds effective subsequences of dependency
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.4812622, 0.0, 0.0, 0.0, 3.4812622, 0.0, -0.26190186, 0.0, 0.0, 0.0, 0.0, -0.27282715, -0.16369629, 3.4812622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4812317, 0.0, 3.4921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771]

Penn Treebank-style phrase structure trees
	10.0
	[0.0, 0.0, 0.0, 6.0894775, -0.37106323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0785522, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0894775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0785522, 0.0, 0.0, 0.0, 0.0]

paths. For the PTB representation, we directly en-
	9.860465
	[0.0, 0.0, 0.0, 0.0, 0.0, 7.279007, -0.15277863, 0.0, 4.0160065, 0.0, 0.0, 4.0174713, 0.0, 0.0, 4.028473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.354309, 0.0, 4.0269165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0269165, 0.0, 0.0]

without function tags and empty nodes. This is the
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3066711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3175964, 0.0, 0.0, 0.0, 3.3175964, 0.0, 0.0, 3.3066711, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, 0.0, 0.0, 0.0, 0.0, 5.140045, 0.0, 0.0, 0.0, 3.3066406, 0.0, 3.317566, 0.0, 0.0]

code phrase structure trees.
	10.0
	[0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0]

default output format for phrase structure parsers.
	10.0
	[0.0, 0.0, -0.098236084, 0.0, 0.0, 0.0, 4.4306946, 0.0, 0.0, 0.0, 0.0, 0.0, 4.452545, 0.0, 0.0, 0.0, 0.0, 0.0, 4.44162, 0.0, 0.0, 4.44162, 0.0, 0.0, 0.0, 0.0, 0.0, 4.452545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4415894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

We also create this representation by converting
	10.0
	[-0.8621216, 5.7184143, 0.0, 0.0, 0.0, 5.740265, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7293396, 0.0, 0.0, 0.0, 5.72937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7402344, 0.0, 5.7293396, 0.0, 0.0, -0.42559814, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0]

Conversion of parse representations
	10.0
	[0.0, 0.0, -0.41469574, -0.10913086, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173615, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 2.7282715, -0.18551636, 0.0, 0.0, -0.19644165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

ENJU’s output by tree structure matching, although
	9.818182
	[0.0, 0.0, 0.0, 0.011810303, -0.58929443, 3.7431946, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7540894, 0.0, 3.7541199, 0.0, 0.0, 0.0, 3.7540894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7541199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.015991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

It is widely believed that the choice of representa-
	10.0
	[0.0, 3.8632202, 0.0, 3.8632278, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8741379, 0.0, 0.0, 0.0, 0.0, -0.2619171, -0.16369629, 0.0, 3.8523102, 0.0, 0.0, 0.0, 3.8741302, 0.0, 0.0, 3.8632202, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8632202, 0.0, 3.8741455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

this conversion is not perfect because forms of PTB
	9.860465
	[0.0, 0.0, 0.0, 3.3394165, 0.0, 0.0, -0.42559814, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 3.339386, 0.0, 3.3503113, 0.0, 0.0, 3.339386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3503113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3394165, 0.0, 0.0, 0.0, 0.0, 3.3503113, 0.0, 3.272705, 0.0, 0.0]

tion format for parser output may greatly affect the
	10.0
	[0.0, 0.0, 0.0, 3.3066635, 0.0, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, 0.0, 3.317566, 0.0, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, 0.0, 3.317566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, -0.26190186, 0.0, 0.0, 0.0, 3.3066711, 0.0, 0.0]

and ENJU’s output are not necessarily compatible.
	9.813953
	[0.0, 0.0, 2.726715, 0.0, 0.0, 0.0, 0.011779785, -0.6002197, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

performance of applications, although this has not
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.059662, 0.0, 4.059662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.397949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0705566, 0.0, 0.0, 0.0, 4.059662, 0.0, 0.0, 4.070587, 0.0, 0.0]

been extensively investigated. We should therefore
	10.0
	[0.0, 0.0, 0.0, 3.4812622, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, -0.27282715, -0.16369629, 0.0, 0.0, 3.470337, 0.0, -0.4256134, -0.16369629, 0.0, 0.0, 0.0, 0.0, -0.05456543, 0.0, 0.0, 0.0, 0.0, 5.642029, -0.8621521, 3.4703674, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

evaluate the parser performance in multiple parse
	10.0
	[-0.27282715, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6707916, 0.0, 0.0, 4.6707916, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6707764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6707764, 0.0, 4.6707764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.670807, 0.0, 0.0, 0.0, 0.0]

ing PTB trees. We first determine lexical heads of
	9.853659
	[0.0, 0.0, 4.0181274, 0.0, 0.0, 4.018524, 0.0, 0.0, 0.0, 0.0, 0.0, 7.257202, -0.8621216, 4.005066, 0.0, 0.0, 0.0, 4.0160217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0269165, 0.0, -0.15280151, 0.0, 0.0, 0.0, 0.0, 4.005066, 0.0, 0.0, 0.0, 0.0, 4.015991, 0.0]

representations. In this paper, we create multiple
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.654053, 0.0, 4.4852753, 0.0, 0.0, 0.0, 4.49617, 0.0, 0.0, 0.0, 0.0, -0.42559814, 4.910858, 0.0, 4.4961853, 0.0, 0.0, 0.0, 0.0, 0.0, 4.48526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

nonterminal nodes by using Bikel’s implementation
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9574585, 0.0, 0.0, 0.0, 0.0, 2.957428, 0.0, 2.957428, 0.0, 0.0, 0.0, 0.0, 2.957428, 0.0, 0.0, -0.09820557, 0.0, 0.0, -0.6002197, 2.9465332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parse representations by converting each parser’s de-
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.1498642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1607666, 0.0, 2.1498718, 0.0, 0.0, -0.4256134, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1498718, 0.0, 0.0, 0.0, 2.1498718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.58932495, 2.1499023, 0.0, 0.0]

fault output into other representations when possi-
	10.0
	[-0.098220825, 0.0, 0.0, 0.0, 3.972351, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9832764, 0.0, 0.0, 0.0, 3.983261, 0.0, 0.0, 0.0, 0.0, 3.9832458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9941711, 0.0, 0.0, 0.0, 3.9832458, 0.0, 0.0, 0.0, 0.0, 0.0]

ble. This experiment can also be considered to be
	10.0
	[0.0, 0.0, 0.0, 6.6460495, 0.0, 0.0, 0.0, 3.8195648, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8086548, 0.0, 0.0, 3.8195648, 0.0, 0.0, 0.0, 3.8195496, 0.0, 3.8195496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.81958, 0.0, 3.81958, 0.0]

into dependencies between lexical heads.
	10.0
	[0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, -0.15280151, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0]

a comparative evaluation of parse representations,
	10.0
	[4.539833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2619171, -0.16369629, 4.5289154, -0.2619171, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5289154, 0.0, 4.5398254, 0.0, 0.0, 0.0, 0.0, 4.5398254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

thus providing an indication for selecting an appro-
	10.0
	[0.0, 0.0, 0.0, 3.1647873, 0.0, 0.0, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1538696, 0.0, 3.1647797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1647797, 0.0, 0.0, 3.1647644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.164795, 0.0, 3.164795, 0.0, 0.0, 0.0, 0.0, 0.0]

priate parse representation for similar IE tasks.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.7173538, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.728241, 0.0, 2.728241, 0.0, 0.0, 0.0, 0.0, 0.0]

This format was originally proposed for extracting
	10.0
	[0.0, 0.0, 0.0, 3.8086243, 0.0, 0.0, 0.0, 0.0, 0.0, 3.81958, -0.09820557, 0.0, 3.79776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8086548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.81958, 0.0, 0.0, 3.8086548, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Figure 7 shows our scheme for representation
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 5.522003, 5.532913, 0.0, 0.0, -0.2619171, 0.0, 5.5220184, 0.0, 0.0, 5.532913, 0.0, 0.0, 0.0, 0.0, 0.0, 5.522003, 0.0, 0.0, 5.5329285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

dependency relations useful for practical applica-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 5.0309143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.041809, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0527344, 0.0, 0.0, 5.041809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.041809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

conversion. This paper focuses on five representa-
	10.0
	[0.0, 0.0, -0.42560577, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.427788, 0.0, 0.0, 0.0, 3.7431793, 0.0, 0.0, 0.0, 0.0, 3.7540894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7431946, 0.0, 3.743164, -0.26190186, -0.16369629, 3.7431946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

tions as described below.
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.7173538, 0.0, 2.7282639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, -0.26190186, -0.69844055]

vert PTB is attached to the Stanford parser. Although
	9.866667
	[-0.15280151, 0.0, 0.0, 2.4483643, 0.0, 0.0, 2.4780884, 0.0, 2.4554138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.466339, 0.0, 2.4663696, 0.0, 0.0, 2.4663696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.466339, 0.0, 0.0, 0.0, 0.0, 0.0, -0.58932495, 3.2848206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

the concept looks similar to CoNLL, this representa-
	9.777778
	[0.0, 0.0, 3.1756897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1866455, 0.0, 0.0, 0.0, 0.0, 3.186615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1756897, 0.0, 3.1397705, 0.0, 0.0, 0.0, 0.0, 0.01550293, 3.1756897, 0.0, 0.0, 0.0, 3.1866455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The dependency tree format used in the
	10.0
	[0.0, 0.0, 5.0527496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15278625, 5.0527496, 0.0, 0.0, 0.0, 5.0527344, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0636597, 0.0, 0.0, 0.0, 5.0636597, 0.0, 5.0527344, 0.0, 0.0]

2006 and 2007 CoNLL shared tasks on dependency
	10.0
	[0.0, 0.0, 0.0, 2.9028702, 0.0, 0.0, 2.9028778, 0.0, 0.0, 0.0, 2.9028778, 0.0, 0.0, 0.0, 0.0, 2.9137878, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9028625, 0.0, 0.0, 0.0, 0.0, 2.902893, 0.0, 2.9137573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771]

http://nlp.cs.lth.se/pennconverter/
	7.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parsing. This is a representation format supported by
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1647797, 0.0, 0.0, 0.0, 2.073471, 0.0, 2.073471, 2.0843964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0734863, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0734863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0844116, 0.0]

http://www.cis.upenn.edu/˜dbikel/software.
	7.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

several data-driven dependency parsers. This repre-
	10.0
	[0.0, -0.27282715, -0.15278625, 0.0, 0.0, 0.0, 2.9683533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2619171, -0.16369629, 0.0, 2.9792786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 2.979248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.157898, 0.0, 0.0, 0.0, 2.9901733, 0.0, 0.0, 0.0, 0.0, 0.0]

with a Penn Treebank-style treebank, we use those
	10.0
	[0.0, 0.0, 0.0, 3.5576477, 3.5576477, 0.0, 0.0, 0.0, 3.5576782, -0.3710327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.546753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.77594, 0.0, 3.5576477, 0.0, 0.0, 3.5576172, 0.0, 0.0, 0.0, 0.0]

programs as-is. Default parameter settings are used
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0993042, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4961853, 0.0, 0.0, -0.09820557, 0.0, 0.0, 0.0, 3.0993347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0993042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0993347, 0.0, 0.0, 3.0993042, 0.0, 0.0, 0.0]

for this parser re-training.
	10.0
	[0.0, 0.0, 2.728241, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

In preliminary experiments, we found that de-
	10.0
	[0.0, 5.15094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1618958, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.7511597, 0.0, 5.1618958, 0.0, 0.0, 0.0, 0.0, 5.161865, 0.0, 0.0, 0.0, 5.161865, 0.0, 0.0]

Figure 9: Stanford dependencies
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 3.0884552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

pendency parsers attain higher dependency accuracy
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 2.313568, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3244934, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3244934, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3244934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 2.3135986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771]

when trained only with GENIA. We therefore only
	10.0
	[0.0, 0.0, 0.0, 3.4812622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4921875, 0.0, 0.0, 0.0, 3.4812622, 0.0, 0.0, 0.0, 3.4921875, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4812622, -0.8621216, 3.4812622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4812622, 0.0, 0.0, 0.0]

input GENIA as the training data for the retraining
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.4267273, 0.0, 0.0, 0.0, 0.0, 3.437622, 0.0, 3.4267273, 0.0, 0.0, 3.4375916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4266968, 0.0, 0.0, 0.0, 3.437622, 0.0, 0.0, 3.4267273, 0.0, 0.0, 3.437622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

tion does not necessarily form a tree structure, and is
	10.0
	[0.0, 0.0, 0.0, 2.3353958, 0.0, 0.0, 0.0, 2.3353958, 0.0, 0.0, 2.3353882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3354034, 0.0, 0.0, 0.0, 2.3353882, 2.3354187, 0.0, 0.0, 0.0, 2.3354187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4117737, 0.0, 0.0, 2.3353882, 0.0]

of dependency parsers. For the other parsers, we in-
	10.0
	[0.0, 2.7719116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 2.7609863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5249023, -0.152771, 0.0, 2.7719116, 0.0, 0.0, 2.7719116, 0.0, 0.0, 0.0, 0.0, 2.7719116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7937317, 0.0, 2.7719116, 0.0, 0.0]

designed to express more fine-grained relations such
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3790512, 0.0, 2.3790436, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3681335, 0.0, 0.0, 0.0, 2.3790588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3899536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3790283, 0.0, 0.0, 0.0]

put the concatenation of WSJ and GENIA for the
	10.0
	[0.0, 0.0, 4.190613, 0.0, 0.0, 4.1906433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.190613, 0.0, 4.190613, 0.0, 0.0, 4.1906433, 0.0, 0.0, 4.1906433, 0.0, 0.0, 0.0, 0.0, 4.190613, 0.0, 0.0, 4.190613, 0.0, 0.0]

as apposition. Research groups for biomedical NLP
	10.0
	[0.0, 2.8483047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7759094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8483124, 0.0, 0.0, 0.0, 0.0, 0.0, 2.859192, 0.0, 0.0, 2.859192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.859192, 0.0, 0.0]

retraining, while the reranker of RERANK was not re-
	9.727273
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4335938, 0.0, 0.0, 0.0, 0.0, 2.368103, 0.0, 0.0, 2.368103, 0.0, 0.0, 0.0, 0.0, 0.0, -0.09820557, 0.0, 2.3572388, 0.0, 2.325531, 0.0, 0.0, 0.0, 0.0, 0.0, 2.386139, -0.10913086, 0.0, 2.3572083, 0.0, 0.0, 2.368103, 0.0, 0.0]

recently adopted this representation for corpus anno-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1498642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1498718, 0.0, 0.0, 0.0, 2.1607819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1498718, 0.0, 0.0, 2.1498718, 0.0, 0.0, 0.0, 0.0, 0.0, 2.160797, 0.0, 0.0, 0.0, 0.0]

trained due to its cost. Since the parsers other than
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.339386, 0.0, 0.0, 3.3502808, 0.0, 3.3394165, 0.0, 0.0, 3.3502808, 0.0, 0.0, 0.0, 0.0, 5.2382507, 0.0, 0.0, 0.0, 0.0, 3.3394165, 0.0, 0.0, 3.3503113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3394165, 0.0, 0.0, 0.0, 0.0, 3.3502808, 0.0, 0.0, 0.0]

NO-RERANK and RERANK require an external POS
	9.210526
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2247314, 0.0, 0.0, 4.1971436, 0.0, 0.0, 0.0, 0.0, 0.0, 4.226654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.190613, 0.0, 4.212433, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.190613, 0.0, 0.0]

tagger, a WSJ-trained POS tagger is used with WSJ-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, -0.42559814, 2.4990845, 2.4554443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4554443, 0.0, 0.0, 2.4554443, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4554443, 0.0, 2.4554443, 0.0, 0.0, 0.0, 2.4554443, 0.0, 0.0, 0.0, 2.4553833, 0.0, 0.0, 0.0]

Predicate-argument structures. This is the de-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.19644165, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8592224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8195496, 0.0, 0.0, 0.0, 2.8810425, 0.0, 2.8701477, 0.0, 0.0, 2.8810425, 0.0, 0.0]

fault output format for ENJU and ENJU-GENIA.
	9.263158
	[-0.098220825, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173538, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 2.6971283, 0.0, 0.0, 0.0, 2.742508, 0.0, 0.0, 2.7167358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022491455]

Although only CoNLL is available for depen-
	9.72973
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.4605255, 0.0, 0.0, 0.0, 6.457123, 0.0, 0.0, 0.0, 0.0, 6.477234, 0.0, 6.4605255, -0.20733643, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.460541, 0.0, 0.0, 6.482361, 0.0, 0.0, 0.0, 0.0, 0.0]

Experiments
	11.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

dency parsers, we can create four representations for
	10.0
	[0.0, 0.0, 0.0, -0.15278625, 2.3244858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.422699, 0.0, 2.3354034, 0.0, 0.0, 2.3353882, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3463135, 0.0, 0.0, 0.0, 2.3353882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3463135, 0.0, 0.0]

the phrase structure parsers, and five for the deep
	10.0
	[0.0, 0.0, 4.3106613, 0.0, 0.0, 0.0, 0.0, 0.0, 4.3106613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.310669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.7035217, 0.0, 0.0, 4.3106384, -0.26190186, -0.16369629, 4.2997437, 0.0, 0.0, 4.321594, 0.0, 0.0, 4.310669, 0.0, 0.0, 0.0]

Experiment settings
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parsers. Dotted arrows in Figure 7 indicate imper-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.209526, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6777039, 0.0, 0.0, 0.0, -0.26193237, 0.0, 3.6558685, 0.0, 3.6776886, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6776733, 3.6667786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6777039, 0.0, 0.0, 0.0, 0.0, -0.20736694]

In the following experiments, we used AImed
	10.0
	[0.0, 7.03891, 0.0, 0.0, 7.049835, 0.0, 0.0, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 7.028015, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.119293, 0.0, 7.0389404, 0.0, 0.0, 0.0, 7.049835, 0.0, 0.0, 0.0, 0.0]

fect conversion, in which the conversion inherently
	10.0
	[0.0, 0.0, 0.0, 3.383049, 0.0, 0.0, -0.42560577, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5358276, 0.0, 3.3830566, 0.0, 0.0, 0.0, 0.0, 3.3830566, 0.0, 0.0, 3.3939514, 0.0, 0.0, -0.42559814, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3721313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

introduces errors, and may decrease the accuracy.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4525223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.889038, 0.0, 0.0, 4.45253, 0.0, 0.0, 4.45253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.452545, 0.0, 0.0, 4.46344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, -0.7093506]

corpus for the evaluation of PPI extraction systems.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.0229187, 0.0, 0.0, 3.0229187, 0.0, 0.0, 3.033844, -0.26190186, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.012024, 0.0, 3.0229187, 0.0, 0.0, 3.033844, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.012024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

We should therefore take caution when comparing
	10.0
	[-0.8621292, 3.9177933, 0.0, 0.0, 0.0, 0.0, 0.0, 3.939621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9286804, 0.0, 0.0, -0.09820557, 3.9286804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.928711, 0.0, 0.0, 0.0, 3.9396057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The corpus consists of 225 biomedical paper ab-
	10.0
	[0.0, 0.0, 4.8781433, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8672485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.878113, 0.0, 4.878113, 0.0, 0.0, 4.8671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8781433, 0.0, 0.0, 0.0, 0.0, 4.878174, 0.0, 0.0]

the results obtained by imperfect conversion. We
	10.0
	[0.0, 0.0, 4.3979645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4088745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4088745, 0.0, 4.4088745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.397949, 0.0, 0.0, -0.42562866, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.413971, -0.8621216]

also measure the accuracy obtained by the ensem-
	10.0
	[0.0, 0.0, 0.0, 3.9396133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.950531, 0.0, 0.0, 3.950531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15278625, 3.9396057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9505005, 0.0, 3.9505005, 0.0, 0.0, 3.950531, 0.0, 0.0, 0.0, 0.0, 0.0]

tokenized, and annotated with proteins and PPIs.
	10.0
	[0.0, 0.0, -0.09820557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.5547485, 0.0, 0.0, 5.009094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9981384, 0.0, 0.0, 0.0, 4.998169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.009094, 0.0, 0.0, 4.998169, 0.0, 0.0, 0.0, 0.0]

ble of two parsers/representations. This experiment
	10.0
	[0.0, 0.0, 3.1320496, 0.0, 3.1320496, 0.0, -0.098220825, 3.121132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.594391, 0.0, 0.0, 0.0, 3.1320496, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

We use gold protein annotations given in the cor-
	10.0
	[-0.8621216, 4.2888184, 0.0, 0.0, 4.310669, 0.0, 0.0, 0.0, 4.2997437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2997437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.310669, 0.0, -0.26190186, -0.16366577, 0.0, 4.2888184, 0.0, 4.310669, 0.0, 0.0, 4.2997437, 0.0, 0.0, -0.20733643]

indicates the differences and overlaps of information
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.248085, 0.0, 0.0, 2.258995, 0.0, 0.0, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2371674, 0.0, 0.0, 2.2590027, -0.152771, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2371826, 0.0, 2.2590027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

pus. Multi-word protein names are concatenated
	10.0
	[0.0, 0.0, 0.0, 9.985413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.09820557, 0.0, 0.0, 4.910858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.932678, 0.0, 0.0, 0.0, 0.0, 4.9217834, 0.0, 0.0, 4.932678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

conveyed by a parser or a parse representation.
	10.0
	[0.0, 0.0, -0.42560577, -0.16369629, -0.16369629, 0.0, 0.0, 2.7173462, 0.0, 2.7282715, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 2.7282562, 2.7282715, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

and treated as single words. The accuracy is mea-
	10.0
	[0.0, 0.0, 3.7104492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7104492, 0.0, 3.7104492, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7104492, -0.09817505, 0.0, 0.0, 0.0, 0.0, 6.3186646, 0.0, 0.0, 3.7104492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 3.699524, 0.0, 3.7104492, 0.0, 0.0, 0.0]

sured by abstract-wise 10-fold cross validation and
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.5031128, 0.0, 3.5140076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5140076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5140076, 0.0, 0.0, 0.0, 0.0, 3.5030823, -0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5031128, 0.0, 0.0]

Domain portability and parser retraining
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.728241, 0.0, 0.0, 0.0, 0.0, 0.0, 2.728241, -0.18551636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Since the domain of our target text is different from
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.9137878, 0.0, 0.0, 2.9137878, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9247131, 0.0, 2.9137878, 0.0, 0.0, 2.9246826, 0.0, 0.0, -0.18553162, 0.0, 0.0, 2.9028625, 0.0, -0.15280151, 0.0, 2.9137878, 0.0, 2.9137878, 0.0, 0.0, -0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9137878, 0.0, 0.0, 0.0]

WSJ, our experiments also highlight the domain
	10.0
	[0.0, 0.0, 0.0, 5.4565277, 0.0, 0.0, 5.4565277, -0.15277863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4456177, 0.0, 0.0, 0.0, 5.456543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4565125, 0.0, 0.0, 5.456543, 0.0, 0.0, 0.0, 0.0, 0.0]

adjust the balance of precision and recall, and the
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 4.103302, 0.0, 0.0, 4.114197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1142273, 0.0, 4.1142273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1033325, 0.0, 0.0, 4.1142273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.452545, 0.0, 0.0, 4.114197, 0.0, 0.0]

portability of parsers. We run two versions of each
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.306656, 0.0, 3.306656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.140045, -0.86213684, 3.2957458, 0.0, 0.0, 3.3066711, 0.0, -0.09820557, 3.3066711, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2957153, 0.0, 3.317566, 0.0, 0.0, 0.0]

maximum f-scores are reported for each setting.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 2.728302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parser in order to investigate the two types of domain
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.1171417, 0.0, 2.1280365, 0.0, 0.0, 0.0, 0.0, 2.1280518, 0.0, 2.1171417, 0.0, -0.4256134, -0.16369629, 0.0, 0.0, 0.0, 0.0, -0.05456543, 0.0, 0.0, 2.1171265, 0.0, 0.0, 2.1280518, 0.0, -0.09820557, 2.1062317, 0.0, 0.0, 0.0, 0.0, 2.1280518, 0.0, 2.1280518, 0.0, 0.0, 0.0, 0.0, 0.0]

portability. First, we run the original parsers trained
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6984329, 3.7322693, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8810425, 0.0, 2.8483124, 0.0, 0.0, 2.8483124, 0.0, 0.0, 2.8483124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.859192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.848297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Comparison of accuracy improvements
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, -0.18551636, -0.10913086, -0.10913086, 0.0, 0.0, 0.0, 0.0, 0.0]

with WSJ
	10.0
	[0.0, 0.0, 0.0, 3.8195724, 0.0, 0.0]

Tables 1 and 2 show the accuracy obtained by using
	10.0
	[-0.8621216, 0.0, 0.0, 0.0, 0.0, 2.7828064, 2.7937622, 0.0, 0.0, 2.7937622, 2.782837, 0.0, 0.0, -0.26193237, 2.782837, 0.0, 0.0, 2.7937622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 2.782837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7937317, 0.0, 2.7937622, 0.0, 0.0, 0.0, 0.0]

setting indicate the domain portability of the original
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1826096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1826172, 0.0, 0.0, 2.1826172, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1935272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1826172, 0.0, 2.1826172, 0.0, 0.0, 2.1935425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

the output of each parser in each parse representa-
	10.0
	[0.0, 0.0, 3.743164, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7322693, 0.0, 3.743164, 0.0, 0.0, 0.0, 3.7431946, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7431946, 0.0, 3.7322693, 0.0, 0.0, 0.0, 3.7431946, 0.0, 0.0, 0.0, 0.0, 3.743164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parsers. Next, we run parsers re-trained with GE-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.1153107, 0.0, -0.15278625, 0.0, 0.0, 4.2779083, 0.0, 3.983261, 0.0, 0.0, 3.972351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.972351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.972351, 0.0, 0.0, 0.0, 3.9832458, 0.0, 0.0]

tion. The row “baseline” indicates the accuracy ob-
	10.0
	[0.0, 0.0, 0.0, 0.0, 4.387085, 0.0, 0.0, 3.0665588, 0.0, -0.26193237, 3.0447388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0665588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0665588, 0.0, 0.0, 3.055664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 3.055664, 0.0, 0.0]

tained with bag-of-words features. Table 3 shows
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 4.1469727, 0.0, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.09820557, 0.0, 0.0, 0.0, 4.1360474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.6609497, -0.8621216, 0.0, 0.0, 0.0, 4.1360474, 4.157898, 0.0, 0.0, -0.26190186, 0.0]

style treebank of biomedical paper abstracts. Accu-
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.012001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0120087, 0.0, 3.0119934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0119934, 0.0, 0.0, 0.0, 0.0, 3.0119934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.234253, 0.0, 0.0, 0.0, 0.0]

the time for parsing the entire AImed corpus, and
	10.0
	[0.0, 0.0, 4.103302, 0.0, 0.0, 0.0, 4.114197, 0.0, 0.0, 4.1033325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1142273, 0.0, 0.0, 4.1142273, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1033325, 0.0, 0.0, 0.0, 0.0, 4.114197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4525146, 0.0, 0.0]

racy improvements in this setting indicate the pos-
	10.0
	[0.0, 0.0, -0.15277863, 3.7104416, 0.0, 0.0, 0.0, 0.0, -0.15278625, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7213593, 0.0, 3.732254, 0.0, 0.0, 0.0, 3.7322693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.721344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7322693, 0.0, 0.0, 3.7322693, 0.0, 0.0, 0.0]

Table 4 shows the time required for 10-fold cross
	10.0
	[-0.8621216, 0.0, 0.0, 0.0, 4.245178, 4.2561035, 0.0, 0.0, -0.26193237, 0.0, 4.245178, 0.0, 0.0, 4.2561035, 0.0, 0.0, 0.0, 4.2669983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2561035, 0.0, 0.0, 4.2561035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2561035, 0.0, 0.0, 0.0, 0.0]

sibility of domain adaptation, and the portability of
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2411728, 0.0, 3.2520828, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2520905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3721313, 0.0, 0.0, 3.2520752, 0.0, 0.0, 3.2520752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2521057, 0.0]

validation with GENIA-retrained parsers.
	10.0
	[-0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

the training methods of the parsers. Since the parsers
	10.0
	[0.0, 0.0, 2.117134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1280518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1280518, 0.0, 2.1280518, 0.0, 0.0, 2.1280365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1756897, 0.0, 0.0, 0.0, 0.0, 2.1280518, 0.0, 0.0, 2.1280518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

listed in Section 2 have programs for the training
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 4.387047, 0.0, 4.387047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.387039, 4.3870544, 0.0, -0.20735168, -0.16369629, 4.3761444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.3870544, 0.0, 0.0, 4.387024, 0.0, 0.0, 4.3870544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Some of the parser packages include parsing models
	8.0
	[0.0, 0.0, 0.0, 5.467125, 0.0, 5.476097, 0.0, 0.0, 5.4761047, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4760895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4761047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4761047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.476074, 0.0, 0.0, 0.0, 0.0, 0.0]

of accuracy — a significantly better result than the
	10.0
	[0.0, 3.5249023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 3.5249023, 3.5249023, 3.5249023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5358582, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5249023, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5358582, 0.0, 0.0, 0.0, 3.5249023, 0.0, 0.0]

trained with extended data, but we used the models trained with
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0613785, 0.0, 0.0, 0.0, 2.0613708, -0.12547302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0524292, 0.0, 0.0, 0.0, 0.0, 2.097229, -0.17030334, 0.0, 2.0524292, 0.0, 2.070343, 0.0, 0.0, 0.0, 2.0613708, 0.0, 0.0, 2.0613708, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0613708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0613708, 0.0, 0.0, 0.0]

baseline. To the extent of our knowledge, this is
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.588562, -0.8621216, 4.452545, 0.0, 0.0, 4.46344, -0.152771, 0.0, 0.0, 0.0, 0.0, 4.452545, 0.0, 4.46344, 0.0, 0.0, 4.46344, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8890686, 0.0, 0.0, 0.0, 4.46344, 0.0]

WSJ section 2-21 of the Penn Treebank.
	8.0
	[0.0, 0.0, 2.231659, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.240631, 0.0, 0.0, 0.0, 2.2406158, 0.0, 2.240631, 0.0, 0.0, 2.240631, 0.0, 0.0, 0.0, 2.240631, -0.30473328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

the first result that proves that dependency parsing,
	10.0
	[0.0, 0.0, 3.4266663, 0.0, 0.0, 0.0, 3.4267273, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4266968, 0.0, 0.0, 0.0, 3.4266968, 0.0, 0.0, -0.152771, -0.16366577, 0.0, 3.4266968, 0.0, 0.0, 0.0, 3.4266968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 3.4157715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The domains of GENIA and AImed are not exactly the
	8.0
	[0.0, 0.0, 3.7642517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7821808, 0.0, 3.7732239, 0.0, 0.0, 0.0, 0.0, 3.7732239, 0.0, 0.0, 3.7821808, 0.0, 0.0, 0.0, 0.0, 3.7731934, 0.0, 0.0, 3.7821655, 0.0, 0.0, 3.7732239, -0.12548828, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7732239, 0.0, 0.0]

phrase structure parsing, and deep parsing perform
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.5794983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.590393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7977295, 0.0, 0.0, 3.5794983, 0.0, 0.0, 0.0, 3.590393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5794678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

same, because they are collected independently.
	8.0
	[0.0, 0.0, 0.0, 0.0, 2.2406235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2316666, 0.0, 0.0, -0.116500854, 2.2316742, 0.0, 0.0, 2.240631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.240631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5736084]

baseline
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

NO-RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0]

BERKELEY
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

STANFORD
	8.0
	[0.0, -0.83351135, 0.0, 0.0, 0.0, 0.0, 0.0]

baseline
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

NO-RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0]

BERKELEY
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

STANFORD
	8.0
	[0.0, -0.83351135, 0.0, 0.0, 0.0, 0.0, 0.0]

ENJU-GENIA
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

WSJ-trained
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

GENIA-retrained
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

baseline
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

NO-RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0]

NO-RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

BERKELEY
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0]

STANFORD
	8.0
	[0.0, -0.83351135, 0.0, 0.0, 0.0, 0.0, 0.0]

BERKELEY
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

STANFORD
	8.0
	[0.0, -0.8334961, 0.0, 0.0, 0.0, 0.0, 0.0]

ENJU-GENIA
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

ENJU-GENIA
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

equally well in a real application.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.954521, 0.0, 0.0, 0.0, 4.9654465, 0.0, 4.965439, 4.965439, 0.0, 0.0, 0.0, 4.965454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Among these
	10.0
	[0.0, 0.0, 0.0, 0.0, 4.965454, 0.0, 0.0, 0.0, 0.0]

retraining yielded only slight improvements for
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.766083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.755188, 0.0, 0.0, 0.0, 6.766083, 0.0, 0.0, 0.0, 0.0, 0.0, 6.766083, 0.0, 0.0, 0.0, 0.0, -0.152771, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 6.755188, 0.0, 0.0]

parsers, RERANK performed slightly better than the
	9.727273
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6764069, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5164185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5030823, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5030823, 0.0, 0.0, 0.0, 3.5030823, 0.0, 0.0]

RERANK, BERKELEY, and STANFORD, while larger
	8.871795
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0154418945, 4.6437683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020935059, 4.638031, 0.0, 0.0, 4.643036, 0.0, -0.8334961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012451172, 4.6380615, 0.0, 0.0, 0.0, 0.0, 4.6490173, 0.0, 0.0, -0.18548584, 0.0, 0.0]

other parsers, although the difference in the f-score
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.2957382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.437622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2957458, 0.0, 0.0, 3.2957458, 0.0, 0.0, -0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2848206, 0.0, 3.2957458, 0.0, 0.0, 3.2957458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

improvements were observed for MST, KSDEP, NO-
	9.45
	[0.0, 0.0, 0.0, 0.0, -0.15280151, -0.16366577, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8850708, 0.0, 0.0, 0.0, 3.8850403, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 0.0, 3.8850708, 0.0, 0.0, 3.8470154, 0.0, 0.0, 0.008239746, 3.8935852, 0.0, 0.0, 0.0, 0.0, 0.0037231445, 3.8935547, 0.0, 0.0]

is small, while it requires much higher parsing cost.
	10.0
	[0.0, 2.7173538, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282639, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 2.728241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.728241, 0.0, 0.0, 0.0, 0.0]

RERANK, and ENJU. Such results indicate the dif-
	9.512196
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0154418945, 4.7035217, 0.0, 0.0, 4.687561, 0.0, 0.0, 0.0, 0.011779785, 4.7035522, 0.0, 0.0, 0.0, 4.692627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.7035217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.7035522, 0.0, 0.0, 4.703491, 0.0, 0.0, 0.0]

ferences in the portability of training methods. A
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1578674, 0.0, 4.1469727, 0.0, 0.0, 4.157898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1578674, 0.0, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.6609497]

large improvement from ENJU to ENJU-GENIA shows
	9.317073
	[0.0, 0.0, -0.18551636, 0.0, 2.6409607, 0.0, 0.0, 0.0, 0.0, -0.152771, -0.16366577, 0.0, 0.0, 0.0, 0.0, 2.6518555, 0.0, 0.0, 0.0, 2.6201172, 0.0, 0.0, 0.0, 2.6725464, 0.0, 2.6528015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6832886, 0.0, 0.0, -0.27282715, 0.0]

strating that the WSJ-trained parsers are not suffi-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1251373, 0.0, 0.0, 0.0, 4.1360397, 0.0, 0.0, 4.1360474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1360474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1360474, 0.0, 0.0, 4.1360474, 0.0, 0.0, 4.1360474, 0.0, 0.0, -0.26190186, 0.0]

the effectiveness of the specifically designed do-
	10.0
	[0.0, 0.0, 5.3037415, 0.0, -0.26190186, 0.0, 0.0, 0.0, 0.0, -0.27282715, -0.16366577, 0.0, 0.0, 0.0, 0.0, 5.292816, 0.0, 5.292816, 0.0, 0.0, 5.303711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.3037415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.303711, 0.0, 0.0]

ciently domain-independent, and that domain adap-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0993042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2084503, 0.0, 0.0, 3.0993042, 0.0, 0.0, 0.0, 3.110199, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1102295, 0.0, 0.0, 0.0, 0.0]

main adaptation method, suggesting that the other
	10.0
	[0.0, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.518036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 4.157898, 0.0, 0.0, 4.157898, 0.0, 0.0, 0.0, 0.0]

tation is effective. It is an important observation that
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.499092, 0.0, 2.5100021, 0.0, -0.2619171, 0.0, 0.0, 0.0, 0.0, -0.27282715, -0.16369629, 0.0, 3.2957458, 0.0, 2.4990845, 0.0, 2.5099945, 0.0, 2.5100098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4990845, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 2.4990845, 0.0, 0.0, 0.0]

parsers might also benefit from more sophisticated
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7650146, 0.0, 0.0, 0.0, 0.0, 3.7650146, 0.0, 0.0, 0.0, 3.7650146, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7650146, 0.0, 0.0, 0.0, 3.7650146, 0.0, 0.0, 0.0, 3.7650146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

the improvements by domain adaptation are larger
	10.0
	[0.0, 0.0, 3.9505234, 0.0, 0.0, 0.0, 0.0, -0.15278625, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 3.950531, 0.0, 3.950531, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9614258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9505005, 0.0, 0.0, 3.9614258, 0.0, 0.0, -0.18551636, 0.0, 0.0]

approaches for domain adaptation.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

than the differences among the parsers in the pre-
	10.0
	[0.0, 0.0, 0.0, 4.1469574, 0.0, 0.0, 4.146965, 0.0, 0.0, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1469727, 0.0, 0.0, 0.0, 0.0, 4.1469574, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1469727, 0.0, 4.146942, 0.0, 0.0, 4.1578674, 0.0, 0.0, 0.0]

While the accuracy level of PPI extraction is
	10.0
	[0.0, 0.0, 0.0, 0.0, 5.8493958, 0.0, 0.0, 5.8493958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 5.838501, 0.0, -0.26190186, -0.16369629, 0.0, 5.8384705, 0.0, 5.860321, 0.0, 0.0, 5.8384705, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.849365, 0.0]

vious experiment. Nevertheless, not all parsers had
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.2520905, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.965439, 0.0, -0.26190186, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3721313, 0.0, 0.0, 3.2630005, 0.0, 0.0, 3.2520752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2630005, 0.0, 0.0]

the similar for the different parsers, parsing speed
	10.0
	[0.0, 0.0, 4.125122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1360474, 0.0, 0.0, 4.1251526, 0.0, 0.0, 4.1360474, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1142273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.48526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1251526, 0.0, 0.0, 0.0, 0.0]

their performance improved upon retraining. Parser
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.9901733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9901733, 0.0, 0.0, 0.0, 0.0, -0.152771, -0.16369629, 0.0, 2.9792633, 0.0, 0.0, 0.0, 2.9901733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.179718, -0.152771, 0.0, 0.0, 0.0, 0.0]

RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0]

RERANK
	8.0
	[0.0, 0.0, 0.0, 0.0, 0.0]

Bag-of-words features
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.099609375, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

differs significantly. The dependency parsers are
	10.0
	[0.0, 0.0, -0.26190948, -0.010917664, 0.0, 0.0, 4.8999634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6984253, 9.898132, 0.0, 0.0, 4.9108887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 4.889038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9108887, 0.0, 0.0]

much faster than the other parsers, while the phrase
	10.0
	[0.0, 0.0, 0.0, 3.012001, -0.098220825, 0.0, 0.0, 0.0, 0.0, 3.0120087, 0.0, 0.0, 0.0, 3.0229187, 0.0, 0.0, 3.0229187, 0.0, 0.0, 0.0, 0.0, 3.0229187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0992737, 0.0, 0.0, 0.0, 0.0, 3.0229187, 0.0, 0.0, 3.0229187, 0.0, 0.0, 0.0, 0.0, 0.0]

structure parsers are relatively slower, and the deep
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2411804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2520905, 0.0, 0.0, 3.2520905, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2619171, -0.16369629, 0.0, 0.0, 3.2411804, 0.0, 0.0, -0.26190186, 0.0, 0.0, -0.43652344, 3.361206, 0.0, 0.0, 3.2520752, 0.0, 0.0, 3.2520752, 0.0, 0.0, 0.0]

parsers are in between. It is noteworthy that the
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6926117, 0.0, 0.0, 4.6926117, 0.0, 4.692627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.287003, 0.0, 4.6926117, 0.0, 4.692627, 0.0, 0.0, 0.0, -0.26190186, -0.10913086, 0.0, 0.0, 0.0, -0.05456543, 4.692627, 0.0, 0.0, 0.0, 4.692627, 0.0, 0.0]

dependency parsers achieved comparable accuracy
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15277863, 4.0269165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0378265, 0.0, 0.0, 0.0, 0.0, -0.2619171, -0.16369629, 0.0, 4.0269165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.037842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771]

This paper
	9.0
	[0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0]

with the other parsers, while they are more efficient.
	10.0
	[0.0, 0.0, 0.0, 2.6518784, 0.0, 0.0, 2.6518707, 0.0, 0.0, 0.0, 0.0, 2.6518707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.662796, 0.0, 0.0, 0.0, 0.0, 2.6518555, 0.0, 0.0, -0.152771, 2.651886, 0.0, 0.0, 2.6518555, 0.0, 0.0, 0.0, 2.6518555, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The experimental results also demonstrate that
	10.0
	[0.0, 0.0, 5.2710114, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2710114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2819214, 0.0, 0.0, 0.0, 5.2819214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.270996, 0.0, 0.0, 0.0]

Table 6: Comparison with previous results on PPI extrac-
	9.0
	[-0.78704834, 0.0, 0.0, 0.0, 2.251587, 0.0, 2.9689026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2615662, 0.0, 0.0, 0.0, 2.2615662, 0.0, 0.0, -0.23910522, 0.0, 0.0, 0.0, 0.0, 2.2515564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2615662, 0.0, 2.2615662, 0.0, 0.0, 2.2615662, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0]

PTB is significantly worse than the other represen-
	9.860465
	[0.0, 0.0, 4.0184784, 0.0, 4.0050964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0160065, -0.09820557, 0.0, 0.0, 0.0, 4.0050964, 0.0, 0.0, 0.0, 4.0050964, 0.0, 0.0, 4.015991, 0.0, 0.0, 0.0, 0.0, 4.015991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

tations with respect to cost for training/testing and
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8304825, 0.0, 0.0, 0.0, 3.8304825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8304749, 0.0, 3.83049, 0.0, 0.0, 0.0, 3.8304749, 0.0, 0.0, 3.8414001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8304749, 0.0, 0.0]

contributions to accuracy improvements. The con-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.20735168, 0.0, 0.0, 0.0, 0.0, 0.0, 3.699524, 0.0, 3.7104187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 3.699524, 0.0, 0.0, 0.0, 0.0, -0.152771, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.3295593, 0.0, 0.0, 3.721344, 0.0, 0.0, 0.0]

potential of a parser. Effectiveness of the parser en-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9683533, 0.0, 2.957428, 2.9683533, 0.0, 0.0, 0.0, 0.0, 0.0, -0.58929443, 4.0923767, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, -0.27279663, -0.16369629, 0.0, 0.0, 0.0, 0.0, 2.957428, 0.0, 2.9574585, 0.0, 0.0, 2.9683533, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9683228, 0.0, 0.0]

version from PTB to dependency-based representa-
	9.860465
	[-0.15277863, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9505234, 0.0, 0.0, 0.0, 3.9563446, 0.0, 0.0, 3.9784698, 0.0, 3.961441, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9614563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

semble is also attested by the fact that it resulted in
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.1756897, 0.0, 3.1756897, 0.0, 0.0, 0.0, 3.1866455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1756897, 0.0, 3.1756897, 0.0, 0.0, 3.186615, -0.09820557, 0.0, 0.0, 3.164795, 0.0, 0.0, 0.0, 3.1756897, 0.0, 3.186615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1756592, 0.0]

tions is therefore desirable for this task, although it
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.2957458, 0.0, 3.2957458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2957458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3066711, 0.0, 0.0, 3.2957458, 0.0, 0.0, 0.0, 3.2957458, 0.0, 0.0, 0.0, 0.0, 3.4485168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2957153, 0.0]

larger improvements. Further investigation of the
	10.0
	[0.0, 0.0, -0.18551636, 0.0, 0.0, 4.46344, 0.0, 0.0, 0.0, 0.0, -0.152771, -0.16366577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.599487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.474365, 0.0, -0.42559814, -0.16369629, 0.0, 0.0, 0.0, 0.0, -0.054534912, 0.0, 0.0, 0.0, 0.0, 4.452545, 0.0, 4.474365, 0.0, 0.0]

is possible that better results might be obtained with
	10.0
	[0.0, 2.6627884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6736908, 0.0, 0.0, 0.0, 2.662796, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6736908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6736908, 0.0, 0.0, 0.0, 0.0, 2.6627808, 0.0, 2.6736755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6736755, 0.0, 0.0, 0.0]

sources of these improvements will illustrate the ad-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.57547, 0.0, 2.5863953, 0.0, 0.0, 0.0, 0.0, 2.5863953, 0.0, 0.0, 0.0, 0.0, -0.152771, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5645447, 0.0, 0.0, 0.0, 2.5863953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5755005, 0.0, 0.0, 2.5864258, 0.0, 0.0]

PTB if a different feature extraction mechanism is
	9.860465
	[0.0, 0.0, 4.4086, 0.0, 4.4088745, 4.4088745, 0.0, 0.0, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 4.397949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4088745, -0.15278625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.397949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4088745, 0.0]

vantages and disadvantages of these parsers and rep-
	10.0
	[-0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3463135, 0.0, 0.0, 2.3572083, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3463135, 0.0, 2.3572388, 0.0, 0.0, 0.0, 0.0, 2.368103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3572083, 0.0, 0.0, 2.3572388, 0.0, 0.0, 0.0]

used. Dependency-based representations are com-
	10.0
	[0.0, 0.0, 0.0, 0.0, 7.3335724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0269165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0487366, 0.0, 0.0, 4.0487366, 0.0, 0.0, 0.0]

resentations, leading us to better parsing models and
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5318298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4881897, 0.0, 2.477234, 0.0, 2.4881897, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4881897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4772644, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4882202, 0.0, 0.0]

petitive, while CoNLL seems superior to HD and SD
	9.560976
	[0.0, 0.0, 0.0, 0.0, 0.0, -0.27282715, -0.15277863, 0.0, 3.7431793, 0.0, 0.0, 0.0, 0.0, 3.524826, 0.0, 0.0, 0.0, 0.0, 3.556427, 0.0, 0.0, 0.0, 0.0, 3.546753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5576782, 0.0, 3.5245056, 0.0, 3.552765, 0.0, 0.0, 3.5369568, 0.0]

a better design for parse representations.
	10.0
	[2.728241, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

in spite of the imperfect conversion from PTB to
	9.85
	[0.0, 5.009094, 0.0, 0.0, 0.0, 0.0, 5.009094, 0.0, 5.009094, 0.0, 0.0, 5.019989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.009094, 0.0, 0.0, -0.42559814, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 4.998169, 0.0, 0.0, 0.0, 4.94812, 0.0, 0.0, 5.0087585, 0.0]

CoNLL. This might be a reason for the high per-
	9.736842
	[0.0, 0.0, 0.0, 0.0, 0.015449524, 4.9872665, 0.0, 0.0, 0.0, 4.987259, 0.0, 0.0, 0.0, 0.0, 4.998184, 0.0, 4.987259, 4.998184, 0.0, 0.0, 0.0, 0.0, 0.0, 4.987274, 0.0, 0.0, 4.987274, 0.0, 0.0, 4.998169, 0.0, 0.0, 0.0, 4.987274, 0.0, 0.0, -0.20733643]

Comparison with previous results on PPI
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 2.7282715, 0.0, -0.18548584, -0.16366577, 0.0, 0.0, 0.0, 0.0, 2.7173462, -0.18551636, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 2.7282715, 0.0, 0.0]

formances of the dependency parsers that directly
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.397957, 0.0, 4.4088745, 0.0, 0.0, 4.4088745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15278625, 4.3870544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4088745, 0.0, 0.0, 0.0, 4.4088745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

extraction
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

compute CoNLL dependencies. The results for ENJU-
	9.581395
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.546669, 0.0, 0.0, 0.0, 0.0, 2.5761566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, 0.0, 2.5645447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.55365, 0.0, 0.0, 2.5255127, 0.0, 0.0, 0.0, 0.011749268]

CoNLL and ENJU-PAS show that PAS contributes to a
	9.268292
	[0.0, 0.0, 0.0, 0.0, 3.216339, 0.0, 0.0, 3.2068558, 0.0, 0.0, 0.0, 0.0017547607, 0.006958008, -0.8245392, 0.0, 3.2125854, 0.0, 0.0, -0.27282715, 3.1975403, 0.0, 0.0, 0.0, 3.2010193, -0.82455444, 0.0, 3.2125854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.21826172, 0.0, 0.0, 0.0, 3.1975403, 0.0, 3.208435]

PPI extraction experiments on AImed have been re-
	10.0
	[0.0, 0.0, 2.902893, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8810425, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8919678, 0.0, 2.9028625, 0.0, 0.0, 0.0, 0.0, 2.902893, 0.0, -0.20733643, -0.16369629, 2.8810425, 0.0, 0.0, 0.0, 2.902893, 0.0, 0.0]

larger accuracy improvement, although this does not
	10.0
	[0.0, 0.0, -0.18552399, 0.0, 0.0, 2.3899612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15278625, 2.400879, 0.0, 0.0, 0.0, 0.0, -0.152771, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4554443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4117737, 0.0, 0.0, 0.0, 2.400879, 0.0, 0.0, 0.0, 2.4118042, 0.0, 0.0]

ported repeatedly, although the figures cannot be
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 5.052765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6984558, 5.6202393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.052765, 0.0, 0.0, 5.0527344, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0527344, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0527344, 0.0]

necessarily mean the superiority of PAS, because two
	9.866667
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2699203, 0.0, 0.0, 0.0, 2.2699127, 0.0, 0.0, 2.2699127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.269928, 0.0, 2.2161865, -0.8155823, 0.0, 0.0026855469, 2.2590027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.269928, 0.0, -0.09820557]

compared directly because of the differences in data
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6628113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6736755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6627808, 0.0, 2.6736755, 0.0, 0.0, 2.6627808, 0.0, 0.0, -0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6628113, 0.0, 2.6627808, 0.0, 0.0, 0.0]

imperfect conversions, i.e., PAS-to-PTB and PTB-to-
	9.608696
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.688614, 0.0, 0.0, -0.4256134, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9177856, 0.0, 0.0, 0.0, 0.0, 3.8947296, -0.8155823, 0.0, 0.0027160645, 0.0, 0.0, 0.0, -0.014007568, 0.0, 0.0, 3.6983948, 0.0, 0.0, 3.6869812, 0.0, 0.0, 0.0073547363, 0.0, 0.0, 0.0]

preprocessing and the number of target protein pairs
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5645447, 0.0, 0.0, 2.5645447, 0.0, 0.0, 2.5645752, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5645447, 0.0, 2.57547, 0.0, 0.0, -0.18551636, 0.0, 0.0, 2.55365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5645752, 0.0, 0.0, 0.0, 0.0]

CoNLL, are applied for creating CoNLL.
	9.393939
	[0.0, 0.0, 0.0, 0.0, 0.015449524, 2.7173462, 0.0, 0.0, 2.7282639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6918335, 0.0, 0.0, 0.0, 0.0, 0.0154418945]

sult with previously reported accuracy figures. Giu-
	10.0
	[0.0, 0.0, 0.0, 2.9137878, 0.0, 0.0, 0.0, 2.9137878, 0.0, 0.0, -0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8919373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9137878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 2.902893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9396362, 0.0, 0.0, 0.0]

Parser ensemble results
	10.0
	[-0.098220825, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, -0.17460632, 0.0, 0.0, 0.0, 0.0, 0.0]

not rely on syntactic parsing, while the former ap-
	10.0
	[0.0, 0.0, 3.7431946, 0.0, 0.0, 0.0, 3.7431946, 0.0, 3.7322693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.743164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9942017, 0.0, 0.0, 0.0, 0.0, 3.7431946, 0.0, 0.0, 3.743164, 0.0, 0.0, 0.0, 0.0, 0.0, 3.743164, 0.0, 0.0]

Table 5 shows the accuracy obtained with ensembles
	10.0
	[-0.8621292, 0.0, 0.0, 0.0, 2.2808228, 2.2917404, 0.0, 0.0, -0.2619171, 0.0, 2.280838, 0.0, 0.0, 2.2917328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 2.280838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.291748, 0.0, 0.0, 0.0, 2.291748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

plied SVMs with kernels on surface strings and the
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.2302551, 0.0, 0.0, 0.0, 3.2302856, 0.0, 0.0, 0.0, 3.2302856, -0.09820557, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2193298, 0.0, 3.2302856, 0.0, 0.0, 0.0, -0.09820557, 0.0, 0.0, 3.2193604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2302551, 0.0, 0.0, 3.2302246, 0.0, 0.0]

latter is similar to our baseline method. Bunescu and
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.2808228, 0.0, 2.291748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.291748, 0.0, 2.2808228, 0.0, 0.0, 2.291748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.291748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2302551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.291748, 0.0, 0.0]

the accuracy with a single parser/representation.
	10.0
	[0.0, 0.0, 6.0676575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15277863, 6.0676575, 0.0, 0.0, 0.0, 6.0676575, 6.0785522, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0785675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

kernels to the same task, although they provided
	10.0
	[-0.09820557, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9763184, 0.0, 4.976349, 0.0, 0.0, 4.987274, 0.0, 0.0, 0.0, 4.987274, 0.0, 0.0, 0.0, 0.0, 5.5438232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.987274, 0.0, 0.0, -0.152771, 4.9763184, 0.0, 0.0, -0.15283203, 0.0, 0.0, 0.0, 0.0]

The results show that the task accuracy significantly
	10.0
	[0.0, 0.0, 2.6846085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6846085, 0.0, 0.0, -0.26190186, 2.6736908, 0.0, 0.0, 0.0, 2.6846008, 0.0, 0.0, 2.6846313, 0.0, 0.0, 0.0, 2.6846008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 2.673706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

only a precision-recall graph, and its f-score is
	10.0
	[0.0, 0.0, 0.0, 6.100403, 6.100403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.089447, 0.0, 0.0, 0.0, 0.0, 0.0, 6.9407043, 0.0, 0.0, 6.100403, 0.0, 0.0, 6.100403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.100403, 0.0]

improves by parser/representation ensemble. Inter-
	10.0
	[0.0, 0.0, 0.0, 0.0, -0.15277863, -0.16369629, 0.0, 3.4812622, 0.0, 3.5030975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5030823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.6966248, 0.0, 0.0, 0.0, 0.0, -0.20733643]

around 50. Since we did not run experiments on
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 4.4197693, 0.0, 0.0, 8.468536, 0.0, 0.0, 0.0, 0.0, 4.4198, 0.0, 4.4306946, 0.0, 0.0, 4.4198, 0.0, 0.0, 4.4197693, 0.0, 0.0, 4.4306946, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4089355, 0.0]

estingly, the accuracy improvements are observed
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6984329, 5.1073074, 0.0, 0.0, 4.6380386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 4.627121, 0.0, 0.0, 0.0, 0.0, -0.15280151, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 4.627136, 0.0, 0.0, 4.648987, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 0.0]

protein-pair-wise cross validation, our system can-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.20733643, 0.0, 0.0, 0.0, 0.0, 3.8850708, 0.0, 0.0, 0.0, 0.0, 3.8959656, -0.26190186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1687927, 0.0, 0.0, 3.8959656, 0.0, 0.0, 0.0, 0.0, 0.0, 3.895935, 0.0, 0.0, 0.0]

even for ensembles of different representations from
	10.0
	[-0.27282715, -0.15278625, 0.0, 2.4554367, 0.0, 0.0, 2.4772644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4772644, 0.0, 2.4772644, 0.0, 0.0, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4663696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4772644, 0.0, 0.0, 0.0]

not be compared directly to the results reported
	10.0
	[0.0, 0.0, 5.652954, 0.0, 5.652954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.652954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.652954, 0.0, 5.6638794, 0.0, 0.0, 5.652954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.652954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

the same parser. This indicates that a single parse
	10.0
	[0.0, 0.0, 3.8523102, 0.0, 0.0, 0.0, 3.8632278, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5893097, 6.777008, 0.0, 0.0, 0.0, 3.8632202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8632202, 0.0, 0.0, 0.0, 3.8632202, 3.8632202, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8632202, 0.0, 0.0, 0.0, 0.0]

representation is insufficient for expressing the true
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2302704, 0.0, 3.2302856, 0.0, 0.0, 0.0, 0.0, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2302704, 0.0, 0.0, 3.2302551, -0.152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2193604, 0.0, 0.0, 3.24115, 0.0, 0.0, 0.0]

sults than theirs in the same evaluation criterion.
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 2.7282639, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 2.7282715, -0.26193237, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Related Work
	11.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9763947, -0.884552, 0.0, 0.0]

tion of these parsers is not straightforward. It is also
	10.0
	[0.0, 0.0, 0.0, 2.6846313, 0.0, 2.673706, 0.0, 0.0, 0.0, 0.0, 2.6846008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6846008, 0.0, 2.6846313, 0.0, 0.0, 2.6846008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.09820557, 0.0, 0.0, 0.0, 3.3502808, 0.0, 2.6846619, 0.0, 2.6846313, 0.0, 0.0, 0.0]

Though the evaluation of syntactic parsers has been
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.9574432, 0.0, 0.0, 2.9574356, -0.2619171, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9574432, 0.0, 2.957428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9683533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.957428, 0.0, 0.0, 2.9683533, 0.0, 0.0, 0.0]

possible to evaluate unsupervised parsers, which is
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5685425, 0.0, 3.568573, -0.26193237, -0.27279663, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5576477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5685425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7868347, 0.0, 0.0, 0.0, 0.0, 3.5685425, 0.0]

a major concern in the parsing community, and a
	10.0
	[4.4088745, 0.0, 0.0, 0.0, 0.0, 4.4197845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4088745, 0.0, 4.4197845, 0.0, 0.0, 4.4088745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6984558, 4.8235474, 0.0, 0.0, 4.4198]

attractive since evaluation of such parsers with gold-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.26193237, -0.16366577, 2.400879, 0.0, 0.0, 0.0, 0.0, 2.422699, -0.26193237, -0.27279663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4117737, 0.0, 2.4117737, 0.0, 0.0, 0.0, 2.4227295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4117737, 0.0, 0.0, 0.0, 2.4226685, 0.0, 0.0, 0.0, 0.0]

couple of works have recently presented the com-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 4.168785, 0.0, 4.168785, -0.098213196, 0.0, 0.0, 0.0, 4.1578827, 0.0, -0.20735168, -0.16369629, 4.1578674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.168762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1687927, 0.0, 0.0, 4.1687927, 0.0, 0.0, 0.0]

standard data is extremely problematic.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 2.7282715, 0.0, 2.7282715, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parison of parsers based on different frameworks,
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5289154, 0.0, 4.539833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5398254, 0.0, 0.0, 0.0, 0.0, 4.5398254, 0.0, 4.539856, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5289, 0.0, 0.0, 0.0, 0.0, -0.26193237, -0.10913086, 0.0, 0.0, 0.0, 0.0]

A major drawback of our methodology is that
	10.0
	[5.063629, 0.0, 0.0, 0.0, 0.0, 5.063629, 0.0, 0.0, -0.152771, 0.0, 0.0, 0.0, 0.0, 5.0636597, 0.0, 5.0745544, 0.0, 0.0, 5.063629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0745544, 0.0, 5.074585, 0.0, 0.0, 0.0]

their methods were based on the comparison of the
	10.0
	[0.0, 0.0, 0.0, 0.0, 3.2739182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2848358, 0.0, 0.0, 0.0, 3.2739105, 0.0, 0.0, 0.0, 0.0, 3.2848358, 0.0, 3.2848206, 0.0, 0.0, 3.2738953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2848206, 0.0, 3.2848206, 0.0, 0.0]

the evaluation is indirect and the results depend
	10.0
	[0.0, 0.0, 5.554718, -0.26190186, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.5438232, 0.0, 5.5656433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.5547485, 0.0, 0.0, 5.5547485, 0.0, 0.0, 5.5656433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.5547485, 0.0, 0.0, 0.0, 0.0, 0.0]

parsing accuracy in terms of a certain intermediate
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6013107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 3.590393, 0.0, 3.6013184, 0.0, 0.0, 0.0, 0.0, 3.6013184, 0.0, 3.6013184, 3.6122131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6012878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

on a selected task and its settings. This indicates
	10.0
	[0.0, 4.2779236, 4.288849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2888184, 0.0, 0.0, 0.0, 4.2779236, 0.0, 0.0, 4.2888184, 0.0, 0.0, 4.2888184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.042938, 0.0, 0.0, 0.0, 4.2888184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

that different results might be obtained with other
	10.0
	[0.0, 0.0, 0.0, 4.212433, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 0.0, 4.212433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2233276, 0.0, 0.0, 0.0, 0.0, 4.2124634, 0.0, 4.223358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.212433, 0.0, 0.0, 0.0, 4.2233887, 0.0, 0.0, 0.0, 0.0]

et al., 2004; Briscoe and Carroll, 2006; Clark and
	10.0
	[0.0, 3.9177856, 0.0, 0.0, 0.0, 4.2233505, 0.0, 0.0, 0.0, 0.0, 4.5289154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9286957, 0.0, 0.0, 3.9177856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2233276, 0.0, 0.0, 0.0, 0.0, 4.5289, 0.0, 0.0, 0.0, 0.0, 3.928711, 0.0, 0.0]

tasks. Hence, we cannot conclude the superiority of
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.721344, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8701172, 0.0, 2.8374023, 0.0, 0.0, 0.0, 0.0, 0.0, 2.848297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8374023, 0.0, 0.0, 2.8483276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8374023, 0.0]

Curran, 2007; Miyao et al., 2007; Clegg and Shep-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4376068, 0.0, 0.0, 0.0, 0.0, 3.6013184, 0.0, 0.0, 0.0, 0.0, 3.2957458, 0.0, 3.3066711, 0.0, 0.0, 0.0, 3.4485168, 0.0, 0.0, 0.0, 0.0, 3.590393, 0.0, 0.0, -0.15280151, 0.0, 3.2957458, 0.0, 0.0, 3.3066406, 0.0, 0.0, 0.0, 0.0]

parsers/representations only with our results. In or-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.186615, 0.0, 0.0, 0.0, 3.186615, 0.0, 0.0, 0.0, 3.1866455, 0.0, 0.0, 3.186615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.7690125, 0.0, 3.1865845, 0.0, -0.20733643]

herd, 2007; Pyysalo et al., 2007b; Pyysalo et al.,
	10.0
	[0.0, 0.0, 0.0, 0.0, 4.856308, 0.0, 0.0, 0.0, 0.0, 5.281929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4416046, 0.0, 4.4306946, 0.0, 0.0, 0.0, 4.8672333, 0.0, 0.0, 0.0, 0.0, 0.0, 5.281891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.430725, 0.0, 4.44162, 0.0, 0.0, 0.0]

der to obtain general ideas on parser performance,
	10.0
	[0.0, 0.0, 3.8850403, 0.0, 3.8850708, 0.0, 0.0, 0.0, 0.0, 0.0, 3.874115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8850708, 0.0, 0.0, 0.0, 0.0, 3.8850708, 0.0, 3.8850708, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8850708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

experiments on other tasks are indispensable.
	10.0
	[-0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

gold standard data in an intermediate representation.
	10.0
	[0.0, 0.0, 0.0, 2.4008713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.400879, 0.0, 0.0, 0.0, 2.411789, 0.0, 2.400879, 0.0, 2.400879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4117737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

However, it has been argued that the conversion of
	10.0
	[0.0, -0.27282715, 0.0, -0.27282715, -0.15278625, 0.0, -0.43652344, 3.7213516, 0.0, 3.5358276, 0.0, 0.0, 3.546753, 0.0, 0.0, 0.0, 3.5358276, 0.0, -0.18553162, 0.0, 0.0, 0.0, 3.5249023, 0.0, 0.0, 0.0, 3.5358276, 0.0, 0.0, 3.5358276, 0.0, 0.0, -0.42559814, -0.15280151, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5249023, 0.0]

Acknowledgments
	11.0
	[0.0, 0.0, 0.0, 0.0, -0.10757446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

parsing results into an intermediate representation is
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5536575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.55365, 0.0, 0.0, 0.0, 2.5536652, 0.0, 2.55365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.55365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.55365, 0.0]

difficult and far from perfect.
	10.0
	[0.0, 0.0, -0.26190948, -0.010910034, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 2.7282715, -0.098220825, 0.0, 2.7173462, 0.0, 0.0, 0.0, 2.7282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

This work was partially supported by Grant-in-Aid
	10.0
	[0.0, 0.0, 0.0, 3.4921875, -0.09820557, 0.0, 0.0, 3.4921875, -0.09820557, 0.0, 3.4921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5030823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4921875, 0.0, 3.5030823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

The relationship between parsing accuracy and
	10.0
	[0.0, 0.0, 4.910881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9217834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.921814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9217834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 4.910858, 0.0, 0.0]

task accuracy has been obscure for many years.
	10.0
	[0.0, 0.0, 0.0, 5.576576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 5.5656586, 0.0, 0.0, 5.5765686, 0.0, 0.0, 0.0, 5.576584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.5765686, 0.0, 0.0, 5.5765686, 0.0, 0.0, -0.15280151, 5.5656433, 0.0, 0.0, 0.0, 0.0, 0.0]

impact of parsing accuracy on statistical MT. How-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.1866074, 0.0, 3.186615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1975403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15278625, 3.1756897, 0.0, 3.1975098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.186615, 0.0, -0.7966614, 3.186615, 0.0, -0.26193237, 0.0]

ever, this work was only concerned with a single de-
	10.0
	[-0.27282715, -0.15278625, 0.0, -0.43652344, 2.5536575, 0.0, 0.0, 0.0, 2.5318298, -0.098220825, 0.0, 0.0, 2.5100098, -0.09820557, 0.0, 2.5209045, 0.0, 0.0, 0.0, 2.5318298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5317993, 0.0, 0.0, 0.0, 2.5209045, 2.5318298, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5318298, 0.0, 0.0]

References
	11.0
	[0.0, 0.0, 0.0, 0.0, -0.20321655, 0.0, 0.0, 0.0, 0.0]

pendency parser, and did not focus on parsers based
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15277863, 2.7719116, 0.0, 0.0, 0.0, 0.0, 0.0, -0.42559814, 2.793747, 0.0, 0.0, 2.782837, 0.0, 0.0, 2.793747, 0.0, 0.0, 2.7828217, 0.0, 0.0, 0.0, 0.0, 2.7937317, 0.0, 2.7828064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7937622, 0.0, 0.0, 0.0, 0.0]

on different frameworks.
	10.0
	[0.0, 2.7173538, 0.0, 0.0, -0.2619171, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7173462, 0.0, 0.0, 0.0, 0.0, -0.26193237, -0.10913086, 0.0, 0.0, 0.0, 0.0]

D. M. Bikel. 2004. Intricacies of Collins’ parsing model.
	9.0
	[0.0, 2.251587, 0.0, 2.2416382, 0.0, 0.0, -0.089660645, 0.0, 0.0, 3.6164856, 0.0, 0.0, 0.0, 0.0, 3.6264343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.251587, 0.0, 2.251587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2416382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2516174, 0.0, 0.0, 0.0, 0.0, 0.0]

Conclusion and Future Work
	11.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9763794, 0.0, 0.0, 2.9883423, 0.0, 0.0, 0.0, 0.0, -0.20321655, 2.9883423, -0.8964844, 0.0, 0.0]

T. Briscoe and J. Carroll. 2006. Evaluating the accu-
	9.0
	[-0.7272949, 3.7559814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7759094, 0.0, 0.0, 3.7659302, 0.0, 3.7659302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.6813354, 0.0, 0.0, 0.0, 0.0, 7.6813354, 0.0, -0.23910522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7659607, 0.0, 0.0, 3.7659302, 0.0, 0.0, 0.0, 0.0]

racy of an unlexicalized statistical parser on the PARC
	9.0
	[0.0, 0.0, -0.14944458, 2.3711243, 0.0, 2.3711548, 0.0, 2.3811035, 0.0, 0.0, 0.0, -0.13949585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.361206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3811035, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3711548, 0.0, 2.3711243, 0.0, 0.0, 2.3811035, -0.90667725, 0.0, 0.0]

We have presented our attempts to evaluate syntac-
	10.0
	[-0.8621292, 3.2957458, 0.0, -0.20735168, -0.16369629, 3.306656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, 0.0, 3.317566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.317566, 0.0, 3.317566, -0.26190186, -0.27282715, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3066406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

DepBank. In COLING/ACL 2006 Poster Session.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5766602, 0.0, 2.4994202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.29888916, 0.0, 2.4807434, 0.0, 0.0, 0.0, 2.4906616, -0.78704834, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010986328]

tic parsers and their representations that are based on
	10.0
	[0.0, 0.0, 2.215355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.226265, 0.0, 0.0, 2.2153473, 0.0, 0.0, 0.0, 0.0, 2.2262726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2262573, 0.0, 0.0, 0.0, 2.215332, 0.0, 0.0, 2.2262573, 0.0, 0.0, 0.0, 0.0, 2.2262573, 0.0]

R. Bunescu and R. J. Mooney. 2004. Collective infor-
	9.0
	[0.0, 3.3773804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3773804, 0.0, 0.0, 3.3773804, 0.0, 3.3773804, 0.0, 3.3773804, 0.0, 0.0, 0.0, 0.0, -0.13946533, -0.647583, 6.406067, 0.0, 0.0, 0.0, 0.0, 6.425995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, -0.1494751, 3.3674316, 0.0, 0.0, 0.0, 0.0, -0.18927002]

different frameworks; dependency parsing, phrase
	10.0
	[0.0, 0.0, -0.26190948, -0.010917664, 0.0, 0.0, 0.0, 0.0, 4.528923, 0.0, 0.0, 0.0, 0.0, -0.26190186, -0.10913086, 0.0, 0.0, 0.0, 0.0, 5.4347076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 4.5289, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.998169, 0.0, 0.0, 0.0, 0.0, 0.0]

mation extraction with relational markov networks. In
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4309082, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4309082, 0.0, 0.0, 0.0, 2.4309082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4408875, 0.0, 0.0, 0.0, -0.089660645, -0.14944458, 2.4309082, 0.0, 0.0, 0.0, -0.089660645, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0]

structure parsing, or deep parsing. The basic idea
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0160065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.343399, 0.0, 4.0269165, 0.0, 0.0, 0.0, 4.0160065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.268097, 0.0, 0.0, 4.0160217, 0.0, 0.0, 0.0, 0.0, 4.0269165, 0.0, 0.0, 0.0]

ACL 2004, pages 439–446.
	9.0
	[-0.29888916, 0.0, 2.480713, 0.0, 0.0, 0.0, 0.012084961, 2.4807434, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

is to measure the accuracy improvements of the
	10.0
	[0.0, 5.4565277, 0.0, 5.4674454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4674377, 0.0, 0.0, 5.4674377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 5.4565125, 0.0, 0.0, 0.0, 0.0, -0.15280151, -0.16369629, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4565125, 0.0, 5.4674377, 0.0, 0.0]

R. C. Bunescu and R. J. Mooney. 2005. Subsequence
	9.0
	[0.0, 3.5267944, 0.0, 3.526825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5367737, 0.0, 0.0, 3.526825, 0.0, 3.5268555, 0.0, 3.5367737, 0.0, 0.0, 0.0, 0.0, -0.13946533, -0.647583, 6.8942566, 0.0, 0.0, 0.0, 0.0, 6.9141846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

PPI extraction task by incorporating the parser out-
	10.0
	[0.0, 0.0, 3.2411804, -0.14186859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2411804, 0.0, 0.0, 0.0, 3.2520905, 0.0, 3.2521057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2520752, 0.0, 0.0, 3.2520752, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2521057, 0.0, 0.0, 0.0]

kernels for relation extraction. In NIPS 2005.
	9.0
	[-0.09963989, 0.0, 0.0, 0.0, 0.0, 0.0, 2.480713, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5766602, 0.0, 2.5015259, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.004333496]

put as statistical features of a machine learning
	10.0
	[0.0, 0.0, 5.914879, 0.0, 5.914871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.914871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.914871, 0.0, 5.9148865, 5.9148865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.914856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

E. Charniak and M. Johnson. 2005. Coarse-to-fine n-
	9.0
	[0.0, 3.6763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6663208, 0.0, 0.0, 3.676239, 0.0, 3.6762695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.362488, 0.0, 0.0, 0.0, 0.0, 7.3724365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6762695, 0.0]

best parsing and MaxEnt discriminative reranking. In
	9.0
	[0.0, 0.0, 0.0, 2.779602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7895813, 0.0, 0.0, 2.7796326, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7895813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, -0.1494751, 2.7696533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.533081, 0.0]

classifier.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.58930206]

Experiments showed that state-of-the-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.4674377, 0.0, 0.0, -0.26190186, 0.0, 0.0, 5.4565125, 0.0, 0.0, 0.0, 5.4783325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

ACL 2005.
	9.0
	[-0.29888916, 0.0, 2.480713, 0.0, 0.0, 0.0, 0.012084961]

art parsers attain accuracy levels that are on par
	10.0
	[0.0, 0.0, 5.249176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2600937, 0.0, 0.0, 0.0, 0.0, 0.0, 5.249176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 5.249176, 0.0, -0.26193237, -0.16369629, 0.0, 0.0, 5.2382507, 0.0, 0.0, 0.0, 5.260071, 0.0, 0.0, 5.249176, 0.0, 5.2601013, 0.0, 0.0]

E. Charniak. 2000. A maximum-entropy-inspired parser.
	9.0
	[0.0, 2.1918335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.636444, 0.0, 0.0, 0.0, 0.0, 3.636444, 2.1818542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.089660645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1818542, 0.0, 0.0, 0.0, 0.0, 0.0, -0.53796387]

with each other, while parsing speed differs sig-
	10.0
	[0.0, 0.0, 0.0, 5.1837006, 0.0, 0.0, 0.0, 5.194618, 0.0, 0.0, 0.0, 0.0, -0.4256134, 5.7948303, 0.0, 0.0, 0.0, 0.0, 5.194626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1946106, 0.0, 0.0, 0.0, 0.0, 5.1946106, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 5.1836853, 0.0, 0.0, 0.0]

In NAACL-2000, pages 132–139.
	9.0
	[0.0, 2.4940186, -0.26901245, 0.0, -0.29888916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0045166016, 2.4807434, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

nificantly. We also found that accuracy improve-
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.69844055, 8.850487, -0.8621216, 4.5507507, 0.0, 0.0, 0.0, 4.5616455, 0.0, 0.0, 0.0, 0.0, 4.5507507, 0.0, 0.0, 0.0, 4.5616455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.152771, 4.5507507, 0.0, 0.0, 0.0, 0.0, -0.15280151, -0.16369629, 0.0]

S. Clark and J. R. Curran. 2004. Parsing the WSJ using
	9.0
	[0.0, 2.819458, 0.0, 0.0, 0.0, 0.0, 2.8194885, 0.0, 0.0, 2.8194885, 0.0, 2.8194885, 0.0, 2.8294373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.642639, 0.0, 0.0, 0.0, 0.0, 4.642639, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8095093, 0.0, 0.0, 2.8194885, 0.0, 0.0, 2.819519, 0.0, 0.0, 0.0, 0.0]

ments vary when parsers are retrained with domain-
	10.0
	[0.0, 0.0, 0.0, 0.0, 2.7500916, -0.2619171, 0.0, 0.0, 2.739174, 0.0, 0.0, 0.0, 2.7500916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7500916, 0.0, 0.0, 2.7500916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7609863, 0.0, 0.0, 0.0, 2.750061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

CCG and log-linear models. In 42nd ACL.
	9.0
	[0.0, 0.0, 2.480713, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.4993591, 0.0, 0.0, 0.0, 2.4807434, -0.28894043, 0.0, -0.007873535]

specific data, indicating the importance of domain
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.059654, 0.0, 0.0, 0.0, 0.0, 4.397949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0596466, 0.0, 0.0, 4.070572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.059662, 0.0, 4.0705566, 0.0, 0.0, 0.0, 0.0, 0.0]

S. Clark and J. R. Curran. 2007. Formalism-independent
	9.0
	[0.0, 2.381134, 0.0, 0.0, 0.0, 0.0, 2.3811035, 0.0, 0.0, 2.3910828, 0.0, 2.3811035, 0.0, 2.3811035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6065369, 0.0, 0.0, 0.0, 0.0, 3.6065369, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

adaptation and the differences in the portability of
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.961441, 0.0, 0.0, 3.961441, 0.0, 0.0, 3.961441, 0.0, 0.0, -0.26193237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.950531, 0.0, 3.9614258, 0.0, 0.0, 3.9614258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.9614563, 0.0]

parser evaluation with CCG and DepBank. In ACL
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.905426, -0.23910522, -0.24905396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8954468, 0.0, 0.0, 0.0, 3.905426, 0.0, 0.0, 3.9153748, 0.0, 0.0, 3.905426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.119659, 0.0, 3.90979, -0.28894043, 0.0]

parser training methods.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.7173538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7282562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Although we restricted ourselves to parsers
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.184784, 0.0, 8.184799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.195709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.15280151, 0.0, 8.184784, 0.0, 8.184784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

A. B. Clegg and A. J. Shepherd. 2007. Benchmark-
	9.0
	[0.0, 4.1046753, 0.0, 4.104645, 0.0, 0.0, -0.13946533, 0.0, 4.084717, 0.0, 0.0, 4.1046753, 0.0, 4.1046753, 0.0, 4.104645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.747314, 0.0, 0.0, 0.0, 0.0, 8.747314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

trainable with Penn Treebank-style treebanks, our
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.561661, 0.0, 0.0, 0.0, 4.572571, 0.0, 0.0, 0.0, 4.5616455, -0.3710327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.561676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.030945, 0.0, 0.0]

ing natural-language parsers for biological applica-
	9.0
	[0.0, 0.0, 4.881775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8917236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.881775, 0.0, 0.0, 4.8917236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.8917236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

methodology can be applied to any English parsers.
	10.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9465332, 0.0, 0.0, 2.9465332, 0.0, 2.946518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9465332, 0.0, 2.9465027, 0.0, -0.15280151, 2.9465332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9465027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

tions using dependency graphs. BMC Bioinformatics,
	9.0
	[0.0, 0.0, 0.0, 0.0, 2.7796326, 0.0, 0.0, 0.0, 0.0, 2.7895813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13946533, 2.779602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5462036, 0.0, 0.0, 2.7796326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0032348633]

M. Collins and N. Duffy. 2002. New ranking algorithms
	9.0
	[0.0, 2.5703964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.580368, 0.0, 0.0, 2.570404, 0.0, 2.5803833, 0.0, 0.0, -0.23908997, 0.0, -0.647583, 3.8456268, 0.0, 0.0, 0.0, 0.0, 3.86557, 0.0, -0.23910522, 2.5604553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5803528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Y. Miyao and J. Tsujii. 2008. Feature forest models for
	9.0
	[-1.275238, 2.919098, 0.0, 0.0, 0.0, 0.0, 2.9290771, 0.0, 0.0, 2.9390259, 0.0, 2.9290771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0013123, 0.0, 0.0, 0.0, 0.0, 4.9913635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9390259, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9290771, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9290771, 0.0, 0.0]

for parsing and tagging: Kernels over discrete struc-
	9.0
	[0.0, 0.0, 3.486969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.496933, 0.0, 0.0, 3.506897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.100952, -0.23910522, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4869995, -0.13949585, -0.14944458, 0.0, 3.486969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4969177, 0.0, 0.0, 0.0, 0.0, 0.0]

probabilistic HPSG parsing. Computational Linguis-
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2478333, 0.0, 0.0, 0.0, 3.257843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.027649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2478333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

tures, and the voted perceptron. In ACL 2002.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 2.4907074, 0.0, 0.0, 2.4906921, -0.18930054, 0.0, 0.0, 0.0, 2.4807281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.4918823, -0.2889099, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.002166748]

Y. Miyao, K. Sagae, and J. Tsujii.
	9.0
	[-1.275238, 4.742279, 0.0, 0.0, 0.0, 0.0, 0.0, 5.3301086, 0.0, 4.7522583, 0.0, 0.0, -0.03982544, 0.0, 0.0, 5.3201294, 0.0, 0.0, 4.7522583, 0.0, 4.7622375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Towards
	9.0
	[-0.78707886, -0.24902344, -0.099609375, 0.0, 0.0, 0.0]

M. Collins. 1997. Three generative, lexicalised models
	9.0
	[0.0, 3.0984268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.5592346, 0.0, 0.0, 0.0, 0.0, 5.5592346, 0.0, 0.0, 0.0, 0.0, 3.1083832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, -0.14944458, 0.0, 3.2478943, 0.0, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0984192, 0.0, 0.0, 0.0, 0.0, 0.0]

framework-independent evaluation of deep linguistic
	9.0
	[0.0, 0.0, 0.0, 0.0, -0.24905396, -0.099609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.825714, -0.23910522, -0.24908447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8157349, 0.0, 3.825714, 0.0, 0.0, 0.0, 3.8356628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

for statistical parsing. In 35th ACL.
	9.0
	[0.0, 0.0, 2.4807281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.493866, 0.0, 0.0, 0.0, 2.4906921, -0.2889099, 0.0, -0.006713867]

parsers. In Grammar Engineering across Frameworks
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.46167, 0.0, -0.14944458, 0.0, 0.0, 0.0, 0.0, 2.4508362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4508667, 0.0, 0.0, -0.4383545, 0.0, 0.0, 2.4408875, -0.5379944, -0.14944458, 0.0, 0.0, -0.13946533, 0.0, 0.0, 0.0, 0.0]

M.-C. de Marneffe, B. MacCartney, and C. D. Man-
	9.0
	[0.0, 0.0, 0.0, 0.0, 4.7821426, 0.0, 4.782135, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, 0.0, 0.0, 5.350006, 0.0, 4.7921143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13949585, -0.647583, 5.3500366, 0.0, 0.0, 4.782135, 0.0, 4.782135, 0.0, 4.7920837, 0.0, 0.0, 0.0]

ning. 2006. Generating typed dependency parses from
	9.0
	[0.0, 0.0, 0.0, 0.0, 3.6663055, 0.0, 0.0, 0.0, 0.0, 3.6762695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.952713, 0.0, 0.0, 0.0, 0.0, 1.9626465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13949585, 1.942749, 0.0, 0.0, 0.0, 0.0, 0.0, 1.9527283, 0.0, 0.0, 0.0]

A. Moschitti. 2006. Making tree kernels practical for
	9.0
	[0.0, 3.7061768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.482025, 0.0, 0.0, 0.0, 0.0, 7.4820557, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7061462, 0.0, 0.0, 0.0, 3.7061462, -0.089660645, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6961975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7061768, 0.0, 0.0]

phrase structure parses. In LREC 2006.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.4926758, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, -0.0021972656]

natural language processing. In EACL 2006.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.4947815, 0.0, -0.2889099, 0.0, 2.4807434, 0.0, 0.0, 0.0, -0.0034484863]

J. M. Eisner.
	9.0
	[0.0, 4.373665, 0.0, 4.3736725, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5379944]

Three new probabilistic models
	9.0
	[0.0, 0.0, 0.0, 0.0, 4.3736725, 0.0, -0.23910522, 4.3637085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.373657, 0.0, 0.0, 0.0, 0.0, 0.0]

J. Nivre and J. Nilsson. 2005. Pseudo-projective depen-
	9.0
	[0.0, 2.8094788, 0.0, -0.23910522, 0.0, 0.0, 2.79953, 0.0, 0.0, 2.7995605, 0.0, 2.8095093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6028137, 0.0, 0.0, 0.0, 0.0, 4.6028137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, -0.1494751, 2.79953, 0.0, 0.0, 0.0, 0.0, 0.0]

for dependency parsing: An exploration. In COLING
	9.0
	[0.0, 0.0, 2.8493576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13948059, 2.8493652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.825714, 0.0, 2.8493347, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.752228, 0.0, 2.8594055, 0.0, 0.0, 0.0, 0.0, 0.0]

dency parsing. In ACL 2005.
	9.0
	[0.0, 0.0, 0.0, -0.14944458, 2.480713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.5009766, -0.29888916, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0020751953]

S. Petrov and D. Klein. 2007. Improved inference for
	9.0
	[0.0, 3.5069275, 0.0, 0.0, 0.0, 0.0, -0.13946533, 3.486969, 0.0, 0.0, 3.506897, 0.0, 3.506897, 0.0, 0.0, 0.0, 0.0, 0.0, 6.8244934, 0.0, 0.0, 0.0, 0.0, 6.8344727, 0.0, 0.0, 0.0, 0.0, -0.13946533, -0.14944458, 0.0, 3.486969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.506897, 0.0, 0.0]

G. Erkan, A. Ozgur, and D. R. Radev. 2007. Semi-
	9.0
	[0.0, 4.144516, 0.0, 0.0, 0.0, 0.0, 0.0, 4.572914, 0.0, 4.144516, 0.0, 0.0, 0.0, 0.0, -0.3885498, 4.5629425, 0.0, 0.0, 4.144516, 0.0, 4.1544952, 0.0, 4.15448, 0.0, 0.0, 0.0, -0.23910522, -0.647583, 8.88681, 0.0, 0.0, 0.0, 0.0, 8.906708, 0.0, 0.0, 0.0, 0.0]

unlexicalized parsing. In HLT-NAACL 2007.
	9.0
	[0.0, 0.0, 0.0, -0.14944458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.480713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.4986877, 0.0, -0.19924927, -0.73724365, 0.0, -0.26901245, 0.0, -0.29888916, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0050354004]

supervised classification for extracting protein interac-
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2515945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2615662, 0.0, 0.0, 2.261551, -0.13949585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2516174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.251587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

S. Pyysalo, T. Salakoski, S. Aubin, and A. Nazarenko.
	9.0
	[0.0, 3.7260742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0249634, -0.7272644, 3.7161255, 0.0, 0.0, 0.0, 0.0, -0.089660645, 0.0, 0.0, 0.0, 0.0, 4.0249634, 0.0, 3.7260742, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0249634, 0.0, 0.0, 3.7260742, 0.0, 3.7260742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.08959961, 0.0]

tion sentences using dependency parsing. In EMNLP
	9.0
	[0.0, 0.0, 0.0, 3.0187225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0187378, 0.0, 0.0, 0.0, 0.0, 3.0286865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13949585, 3.0087585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.3002014, 0.0, 3.024353, 0.0, 0.0, 0.0, 0.0]

Lexical adaptation of link grammar to the
	9.0
	[0.0, -0.13946533, 0.0, 0.0, 0.0, 0.0, 5.090973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.100952, 0.0, 5.100952, 0.0, 0.0, 0.0, 5.100952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1109314, 0.0, 5.100952, 0.0, 0.0]

biomedical sublanguage: a comparative evaluation of
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0585632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.224243, 3.0585938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, -0.14944458, 3.0486145, -0.23910522, -0.24908447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0585327, 0.0]

D. Gildea. 2001. Corpus variation and parser perfor-
	9.0
	[0.0, 3.8755264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.049927, 0.0, 0.0, 0.0, 0.0, 8.049942, 0.0, 0.0, 0.0, 0.0, 0.0, 3.885498, -0.23910522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8755188, 0.0, 0.0, 3.885498, 0.0, 0.0, 0.0, 0.0, 0.0, 3.885498, 0.0, 0.0, 0.0, 0.0, 0.0, -0.18930054]

mance. In EMNLP 2001, pages 167–202.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.576645, 0.0, 2.492775, 0.0, 0.0, 0.0, 0.0, 2.4907074, 0.0, 0.0, 0.0, 0.0011291504, 2.4906921, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

S. Pyysalo, F. Ginter, J. Heimonen, J. Björne, J. Boberg,
	9.0
	[0.0, 2.8095093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8892212, -0.78707886, 2.7995605, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3885193, 2.879242, 0.0, 2.8095093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8891907, 0.0, 2.8095093, 0.0, 0.0039367676, 0.0, 0.0, 0.0, 0.0, 2.8792725, 0.0, 2.8095093, 0.0, 0.0, 0.0, 0.0, -0.16931152, 0.0]

C. Giuliano, A. Lavelli, and L. Romano. 2006. Exploit-
	9.0
	[0.0, 2.7796173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8692932, 0.0, 2.7895966, 0.0, -0.18930054, -0.14944458, 0.0, 0.0, 0.0, 0.0, 2.84935, 0.0, 0.0, 2.7895813, 0.0, 2.7895813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.54303, 0.0, 0.0, 0.0, 0.0, 4.54303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

J. Järvinen, and T. Salakoski. 2007a. BioInfer: a cor-
	9.0
	[0.0, 2.7497253, 0.002166748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8095093, 0.0, 0.0, 2.759674, -0.7272949, 2.7397766, 0.0, 0.0, 0.0, 0.0, -0.089660645, 0.0, 0.0, 0.0, 0.0, 4.4135437, 0.0, 0.0, 0.0, 0.0, 0.0, 4.4234924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.616455, 2.7497559, 0.0, 0.0, -0.18927002]

ing shallow linguistic information for relation extrac-
	9.0
	[0.0, 0.0, 3.1083908, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, 3.1183472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1183472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1183472, 0.0, 0.0, 3.1183777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1183472, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0]

pus for information extraction in the biomedical do-
	9.0
	[0.0, 0.0, 3.736023, 0.0, 0.0, 3.7460327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7559814, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.736023, 0.0, 3.7460327, 0.0, 0.0, 3.7460327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7460327, 0.0, 0.0]

tion from biomedical literature. In EACL 2006.
	9.0
	[0.0, 0.0, 0.0, 2.4807358, 0.0, 0.0, 0.0, 2.4906998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.4904785, 0.0, -0.2889099, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0066223145]

T. Hara, Y. Miyao, and J. Tsujii. 2007. Evaluating im-
	9.0
	[-0.73724365, 3.198059, 0.0, 0.0, 0.0, 0.0, 3.3873444, -1.275238, 3.198059, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3773956, 0.0, 0.0, 3.208023, 0.0, 3.208023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.868103, 0.0, 0.0, 0.0, 0.0, 5.8780518, 0.0, -0.23910522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.198059, 0.0, 0.0]

S. Pyysalo, F. Ginter, V. Laippala, K. Haverinen, J. Hei-
	9.0
	[0.0, 2.9290771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0386658, -0.78704834, 2.9190674, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3885498, 3.0286865, -1.275238, 2.9290771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0386658, 0.0, 2.9290771, 0.0, -0.18930054, -0.1494751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0286865, 0.0, 2.9290771, 0.0, 0.0, 0.0]

pact of re-training a lexical disambiguation model on
	9.0
	[0.0, 0.0, 0.0, 3.1083908, 0.0, 3.1083908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1183472, 3.1183472, 0.0, -0.13948059, 0.0, 0.0, 0.0, 0.0, 3.0984192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1183472, 0.0, 0.0, 0.0, 0.0, 3.1083984, 0.0]

monen, and T. Salakoski. 2007b. On the unification of
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.271515, 0.0, 0.0, 2.2216797, -0.7272644, 2.2117615, 0.0, 0.0, 0.0, 0.0, -0.089660645, 0.0, 0.0, 0.0, 0.0, 3.6264343, 0.0, 0.0, 0.0, 0.0, -0.3885498, 3.6164856, 0.0, 2.2216797, 0.0, 0.0, 2.2217102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2316895, 0.0]

domain adaptation of an HPSG parser. In IWPT 2007.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4807358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 2.4906921, 0.0, 2.4906921, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5379944, 3.5766296, 0.0, 2.493805, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0132751465]

syntactic annotations under the Stanford dependency
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5766296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5965576, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 0.0, 3.586609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13946533]

R. Johansson and P. Nugues.
	9.0
	[0.0, 6.8444366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.8444366, 0.0, 0.0, 6.8444214, -1.0959015, 6.8344727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Extended
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

scheme: A case study on BioInfer and GENIA. In
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.9079285, 3.905426, 0.0, 0.0, 0.0, 3.905426, 0.0, 0.0, 0.0, 0.0, 3.8954468, 0.0, 3.905426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.905426, 0.0, 0.0, 3.905426, 0.0, 0.0, 0.0, 0.0, 0.0, 8.109741, 0.0]

constituent-to-dependency conversion for English. In
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.14944458, 3.0087738, 0.0, 0.0, -0.3885498, -0.14944458, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0087585, 0.0, 0.0, 3.0187378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2703247, 0.0]

BioNLP 2007, pages 25–32.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.00881958, 2.480713, 0.0, 0.0, 0.0, 0.0, 2.4906616, 0.0, 0.0, 0.0, 0.0, 0.0]

NODALIDA 2007.
	9.0
	[0.0, 0.0, -0.34870148, 0.0, 0.0, 0.0, -0.34869385, 2.4807434, 0.0, 0.0, 0.0, 0.00491333]

C. Quirk and S. Corston-Oliver. 2006. The impact of
	9.0
	[0.0, 3.6762695, 0.0, 0.0, 0.0, 0.0, 3.6762695, 0.0, 0.0, 3.6762695, 0.0, 3.6762695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, -0.14944458, 0.0, -0.5479431, 7.362488, 0.0, 0.0, 0.0, 0.0, 7.3824463, 0.0, 0.0, 3.676239, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6762695, 0.0]

R. M. Kaplan, S. Riezler, T. H. King, J. T. Maxwell, and
	9.0
	[0.0, 2.679985, 0.0, 2.679985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7397614, 0.0, 2.6799927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.38856506, 2.7198334, -0.7272949, 2.6799927, 0.0, 2.6799927, 0.0, 0.0, 0.0, 0.0, 2.739746, 0.0, 2.6799927, -0.7272644, 2.6700134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7397766, 0.0, 0.0]

parse quality on syntactically-informed statistical ma-
	9.0
	[0.0, 0.0, 0.0, 0.0, 2.7696838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7895508, 0.0, 2.779602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.779602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.779602, 0.0, 0.0]

A. Vasserman. 2004. Speed and accuracy in shallow
	9.0
	[0.0, 3.0087585, -1.0959091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2703094, 0.0, 0.0, 0.0, 0.0, 5.2902374, 0.0, 0.0, 0.0, 0.0, 3.0187225, 0.0, 0.0, 3.0187378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13946533, 3.0087585, 0.0, 3.0187378, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522]

chine translation. In EMNLP 2006.
	9.0
	[0.0, 0.0, 0.0, 0.0, 2.480713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.493805, 0.0, 0.0, 0.0, 0.0, 2.4906616, 0.0, 0.0, 0.0, 0.0010681152]

and deep stochastic parsing. In HLT/NAACL’04.
	9.0
	[0.0, 0.0, 2.4807281, 0.0, 0.0, 0.0, 2.4906998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5865936, 0.0, 2.4971619, 0.0, -0.19924927, 0.0, 0.0, -0.26901245, 0.0, -0.29888916, 0.0, -0.36862183, 0.0, 0.0, -0.0022888184]

E. K. Ringger, R. C. Moore, E. Charniak, L. Vander-
	9.0
	[0.0, 4.244171, 0.0, 4.2441406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3885193, 4.6725464, 0.0, 4.2441406, 0.0, 4.2441406, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6924744, 0.0, 4.2441406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.6825256, 0.0, 4.2441406, -1.0958862, 0.0, 0.0, 0.0, 0.0, -0.19927979]

S. Katrenko and P. Adriaans. 2006. Learning relations
	9.0
	[0.0, 3.3375397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.089668274, 3.337532, 0.0, 0.0, 3.3375397, -1.0959015, 3.3375397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.306427, 0.0, 0.0, 0.0, 0.0, 6.3164062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3475037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

wende, and H. Suzuki. 2004. Using the Penn Tree-
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 3.6264343, 0.0, 0.0, 3.3973083, 0.0, 3.3973083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.495758, 0.0, 0.0, 0.0, 0.0, 6.505707, 0.0, 0.0, 0.0, 0.0, 3.3973389, 0.0, 0.0, 3.3973083, 0.0, 0.0, 0.0, 3.4072876, -0.33874512, 0.0, 0.0, 0.0]

from biomedical corpora using dependency trees. In
	9.0
	[0.0, 0.0, 0.0, 3.35746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3674164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3574677, 0.0, 0.0, 0.0, 0.0, 3.3674316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13946533, 3.357483, 0.0, 0.0, 0.0, 0.0, 0.0, 6.37619, 0.0]

bank to evaluate non-treebank parsers. In LREC 2004.
	9.0
	[0.0, 0.0, 0.0, 2.3512268, 0.0, 2.3512268, -0.23910522, -0.24908447, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3412476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.361206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6065369, 0.0, 2.3604736, 0.0, 0.0, 0.0, 2.3412476, 0.0, 0.0, 0.0, 0.0071411133]

KDECB, pages 61–80.
	9.0
	[0.0, 0.0, 0.0, 0.0, -0.008888245, 2.4906921, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0]

R. Sætre, K. Sagae, and J. Tsujii.
	9.0
	[0.0, 4.6924744, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2504272, 0.0, 4.6924744, 0.0, 0.0, -0.039855957, 0.0, 0.0, 5.2404175, 0.0, 0.0, 4.702423, 0.0, 4.6924744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Syntactic
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

J.-D. Kim, T. Ohta, Y. Teteisi, and J. Tsujii. 2003. GE-
	9.0
	[0.0, 0.0, 0.0, 0.0, 2.9888306, 0.0, 0.0, 0.0, 3.1183548, -0.72727966, 2.9788666, 0.0, 0.0, 0.0, 0.0, 3.1283264, -1.275238, 2.9788666, -0.68743896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1083984, 0.0, 0.0, 2.9888306, 0.0, 2.9987793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.190613, 0.0, 0.0, 0.0, 0.0, 5.200592, 0.0, 0.0]

features for protein-protein interaction extraction. In
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3674316, 0.0, 0.0, 3.3674316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3773499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3674316, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.396118, 0.0]

NIA corpus — a semantically annotated corpus for
	9.0
	[0.0, 0.0, 4.2740326, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2740326, 4.2839966, 4.284012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.284027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2839966, 0.0, 0.0, 0.0, 0.0, 0.0, 4.274048, 0.0, 0.0]

LBM 2007 short papers.
	9.0
	[0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, -0.089660645, 5.79834E-4]

bio-textmining. Bioinformatics, 19:i180–182.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, -0.14943695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5782013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0022277832, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

K. Sagae and J. Tsujii. 2007. Dependency parsing and
	9.0
	[0.0, 3.217987, 0.0, 0.0, -0.03982544, 0.0, 3.198059, 0.0, 0.0, 3.217987, 0.0, 3.217987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.9079285, 0.0, 0.0, 0.0, 0.0, 5.8979797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.12954712, 3.1980896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2179565, 0.0, 0.0]

D. Klein and C. D. Manning. 2003. Accurate unlexical-
	9.0
	[0.0, 2.739769, 0.0, 0.0, 0.0, 0.0, 2.7397614, 0.0, 0.0, 2.7497253, 0.0, 2.7397766, 0.0, 2.739746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.3936005, 0.0, 0.0, 0.0, 0.0, 4.393585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7497559, 0.0, 0.0, 0.0, -0.13949585, 0.0, 0.0, 0.0, 0.0, 0.0]

domain adaptation with LR models and parser ensem-
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.530548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5404968, 0.0, 0.0, 0.0, 2.5404968, 0.0, 2.5404968, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5404968, 0.0, 0.0, 2.5405273, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5404968, 0.0, 0.0, 0.0, 0.0, 0.0]

ized parsing. In ACL 2003.
	9.0
	[0.0, 0.0, 0.0, 2.4807358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.4927826, -0.2889099, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0021362305]

bles. In EMNLP-CoNLL 2007.
	9.0
	[0.0, 0.0, 0.0, 0.0, 3.5766602, 0.0, 2.502777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0021972656]

D. Lin. 1998. Dependency-based evaluation of MINI-
	9.0
	[0.0, 3.4770126, 0.0, 0.0, 0.0, 6.744812, 0.0, 0.0, 0.0, 0.0, 6.754776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13948059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.467041, -0.23913574, -0.24908447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.467041, 0.0, 3.486969, 0.0, 0.0, 0.0, 0.0]

K. Sagae, Y. Miyao, T. Matsuzaki, and J. Tsujii. 2008.
	9.0
	[0.0, 3.2976685, 0.0, 0.0, -0.029907227, 0.0, 0.0, 3.4969788, -1.275238, 3.2877197, 0.0, 0.0, 0.0, 0.0, 0.0, 3.506897, -0.7272644, 3.297699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.506897, 0.0, 0.0, 3.3076782, 0.0, 3.3076782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.1868896, 0.0, 0.0, 0.0, 0.0]

PAR. In LREC Workshop on the Evaluation of Parsing
	9.0
	[-0.9165802, 0.0, 0.0, 3.6364212, 0.0, 2.1326294, 0.0, 0.0, 0.0, 2.1220856, -0.9066162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1121063, 0.0, 2.1320496, 0.0, 0.0, 2.1220703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1320496, 0.0, 2.1220703, -0.78704834, 0.0, -0.099609375, 0.0, 0.0, 0.0]

Challenges in mapping of syntactic representations
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9913635, 0.0, 4.991333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.9913635, 0.0, 4.9913635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0013123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Systems.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.003364563]

for framework-independent parser evaluation. In the
	9.0
	[0.0, 0.0, 3.4670715, 0.0, 0.0, 0.0, 0.0, -0.23910522, -0.09963989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4570923, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4670715, -0.23910522, -0.24905396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.704956, 0.0, 3.4746094, 0.0, 0.0]

M. Marcus, B. Santorini, and M. A. Marcinkiewicz.
	9.0
	[0.0, 5.1607285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.838196, 0.0, 5.170685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.838196, 0.0, 0.0, 5.160736, 0.0, 5.170685, 0.0, 5.170685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.23910522, 0.0, 0.0, 0.0, 0.0]

Workshop on Automated Syntatic Annotations for In-
	9.0
	[-0.91659546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3275452, 0.0, 3.3275452, -0.18930054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3175964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3275757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3275757, 0.0, 0.0, 3.3375854, 0.0, 0.0]

Building a large annotated corpus of En-
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.5293427, 5.529358, 0.0, 0.0, -0.16937256, 0.0, 5.50943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.529358, 0.0, 0.0, 0.0, 0.0, 0.0, 5.5293274, 0.0, 5.5193787, 0.0, 0.0]

teroperable Language Resources.
	9.0
	[0.0, 0.0, -0.44833374, 0.0, 0.0, 0.0, -0.1494751, 0.0, 0.0, 0.0, 2.480713, 0.0, 0.0, 0.0, 0.0, 0.0, -0.089660645, -0.09963989, 2.4807434, 0.0, 0.0, 0.0, 0.0, 0.0, -0.35864258, 0.0, 0.0, -0.0038146973]

glish: The Penn Treebank. Computational Linguistics,
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 2.8393936, 0.0, 0.0, 2.0124817, 0.0, 0.0, 0.0, 2.0124817, -0.33872986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6593628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0124817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0038146973]

D. D. Sleator and D. Temperley. 1993. Parsing English
	9.0
	[0.0, 2.9987793, 0.0, 2.9888306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9988098, 0.0, 0.0, 2.9987793, 0.0, 2.9987793, -0.68740845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.14944458, -0.647583, 5.1905823, 0.0, 0.0, 0.0, 0.0, 5.2005615, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 2.988861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

with a Link Grammar. In 3rd IWPT.
	9.0
	[0.0, 0.0, 0.0, 2.4807434, 2.4906921, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5379944, 3.5766602, 0.0, 2.4938354, 0.0, -0.35864258, 2.4807434, 0.0, 0.0, 0.0, 0.0073547363]

T. Matsuzaki, Y. Miyao, and J. Tsujii. 2005. Probabilis-
	9.0
	[-0.7372513, 2.739769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8095093, -1.275238, 2.7397614, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8095093, 0.0, 0.0, 2.7497253, 0.0, 2.7497253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.403534, 0.0, 0.0, 0.0, 0.0, 4.413513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Y. Tsuruoka, Y. Tateishi, J.-D. Kim, T. Ohta, J. Mc-
	9.0
	[-1.275238, 4.6227417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1707153, -1.275238, 4.622711, -0.78704834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.160736, 0.0, 0.0, 0.0, 0.0, 4.6426697, 0.0, 0.0, 0.0, 5.1707153, -0.7272644, 4.622711, 0.0, 0.0, 0.0, 0.0, 5.170746, 0.0, 4.6326904, 0.0, 0.0]

tic CFG with latent annotations. In ACL 2005.
	9.0
	[0.0, 0.0, 2.4807358, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.586609, 0.0, 2.49057, -0.2889099, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.002166748]

Naught, S. Ananiadou, and J. Tsujii. 2005. Develop-
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9689026, 0.0, 2.8792725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9788513, 0.0, 0.0, 2.879242, 0.0, 2.879242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.83197, 0.0, 0.0, 0.0, 0.0, 4.83197, 0.0, -0.23913574, -0.1494751, 0.0, 0.0, 0.0, 0.0]

R. McDonald and F. Pereira. 2006. Online learning of
	9.0
	[0.0, 3.3076477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3076477, 0.0, 0.0, 3.3076477, -0.78707886, 3.297699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.1968536, 0.0, 0.0, 0.0, 0.0, 6.2068176, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3076477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3076477, 0.0]

ing a robust part-of-speech tagger for biomedical text.
	9.0
	[0.0, 0.0, 2.630188, 2.6301575, 0.0, 0.0, -0.18930054, 0.0, 0.0, 2.6202087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6301575, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6301575, 0.0, 0.0, 2.6401367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.630188, 0.0, -0.13946533, 0.0, 0.0]

approximate dependency parsing algorithms. In EACL
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0423737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.13948059, 2.0423737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0423584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6662903, 0.0, 2.0425415, 0.0, -0.2889099, 0.0]

In 10th Panhellenic Conference on Informatics.
	9.0
	[0.0, 2.4940186, 0.0, 0.0, 0.0, 2.4807434, -0.78704834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 0.0, 0.0, 0.0, 0.0, -0.35864258, 0.0, 0.0, 0.0, 2.4807434, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0060424805]

A. Yakushiji, Y. Miyao, Y. Tateisi, and J. Tsujii. 2005.
	9.0
	[0.0, 3.3574524, -0.9863281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5567322, -1.275238, 3.3475037, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5766602, -1.275238, 3.3475037, -0.78704834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5567322, 0.0, 0.0, 3.3574524, 0.0, 3.3574524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.3562927, 0.0, 0.0, 0.0, 0.0]

T. Mitsumori, M. Murata, Y. Fukuda, K. Doi, and H. Doi.
	9.0
	[-0.7372513, 2.2117386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.271515, 0.0, 2.2217102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2715302, -1.275238, 2.201767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2714844, 0.0, 2.2217102, 0.0, 0.0, 0.0, 2.271515, 0.0, 0.0, 2.211731, 0.0, 2.2217102, 0.0, 0.0, 0.0]

Biomedical information extraction with predicate-
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.416046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.416046, -0.13946533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.4060364, 0.0, 0.0, 0.0, 6.425995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

2006. Extracting protein-protein interaction informa-
	9.0
	[0.0, 0.0, 0.0, 0.0, 5.479538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0785065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0884705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0784912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

argument structure patterns.
	9.0
	[0.0, -0.1793518, 0.0, 0.0, 0.0, 0.0, 0.0, 4.7522583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.752228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

In First International
	9.0
	[0.0, 4.763092, -0.44833374, 0.0, -0.09963989, 0.0, 4.7423096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

tion from biomedical text with SVM. IEICE - Trans.
	9.0
	[0.0, 0.0, 0.0, 2.9987946, 0.0, 0.0, 0.0, 3.0187225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0087585, 0.0, -0.13949585, 0.0, 3.0087585, 0.0, 0.0, 0.0, 3.0087585, 0.0, 0.0, 0.0, 5.256836, 0.0, 0.0, 0.0, 0.0, 3.0087585, 3.0087585, -0.5379944, -0.14944458, 0.0, 0.0, 0.0]

Symposium on Semantic Mining in Biomedicine.
	9.0
	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4807434, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4906921, 0.0, 2.4906921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005126953]
